{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment Analysis - FinBERT Model.ipynb","provenance":[{"file_id":"1hanAEbSUtce3sriRcFv73Yt4aXgVYDi-","timestamp":1606367638500}],"collapsed_sections":["uoLDnz4cS_rT","s7eUlF47VtuO","xmqEqjMRbgjg","VSQwpM3TY_zX","Vml2o6IreI5F","eGfKcuXALkF4","BtwOZLHRTCUI","0zsllAdoo9Jj"],"authorship_tag":"ABX9TyNtNwDuka8SJrBAwPoehhX1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uoLDnz4cS_rT"},"source":["# FinBert Model Installation\n","\n","https://github.com/ProsusAI/finBERT\n","\n","1.   Requires conda environment\n","2.   Therefore need to install Google Colab Conda dependencies\n","3. Alternative would be to modify installation method/instructions from github repo. ex: install repo denpendencies all via pip only? OR install via docker container?\n","\n","docker setup is quite simple -> https://colab.research.google.com/drive/10OinT5ZNGtdLLQ9K399jlKgNgidxUbGP#scrollTo=6J8LSVAJoSf3\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euwdXBESWdle","executionInfo":{"status":"ok","timestamp":1606429558431,"user_tz":300,"elapsed":1058,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"5db68cbe-e396-4939-94b8-d45f79c372e7"},"source":["!git clone https://github.com/ProsusAI/finBERT.git\n","finBERT_repo_path = '/content/finBERT'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'finBERT'...\n","remote: Enumerating objects: 113, done.\u001b[K\n","remote: Counting objects: 100% (113/113), done.\u001b[K\n","remote: Compressing objects: 100% (72/72), done.\u001b[K\n","remote: Total 113 (delta 49), reused 98 (delta 38), pack-reused 0\u001b[K\n","Receiving objects: 100% (113/113), 42.26 KiB | 8.45 MiB/s, done.\n","Resolving deltas: 100% (49/49), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s7eUlF47VtuO"},"source":["## Install conda envrionement dependencies \n","\n","Following instructions from -> https://datascience.stackexchange.com/questions/75948/how-to-setup-and-run-conda-on-google-colab/75979#75979 -> https://donaldsrepo.github.io/Notebooks/GoogleColabCondaCreateEnv.html\n","\n","Modified for FinBERT"]},{"cell_type":"code","metadata":{"id":"DvNRB1ALV4FY","executionInfo":{"status":"ok","timestamp":1606429558628,"user_tz":300,"elapsed":1248,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}}},"source":["!which conda"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0mS86gSV9Ke","executionInfo":{"status":"ok","timestamp":1606429912636,"user_tz":300,"elapsed":355252,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"e777411c-a63c-45aa-ff89-02948d1b8b66"},"source":["# try to run the bare minimum to get a new conda env working\n","conda_path = ''\n","try:\n","    conda_path = !which conda\n","finally:\n","    print('')\n","\n","if (len(conda_path) == 0):\n","    print('installing miniconda')\n","    !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n","    !conda update conda -y -q\n","    !source /usr/local/etc/profile.d/conda.sh\n","    !conda init \n","    !conda install -n root _license -y -q\n","else:\n","    print('found miniconda')\n","\n","env_name = 'finbert'\n","\n","conda_envs = !conda env list\n","res = [i for i in conda_envs if env_name in i]\n","if (len(res) == 0):\n","    print('not found', env_name, 'env', len(res))\n","    # !conda env create -f environment.yml\n","    # OR\n","    !conda env create -f /content/finBERT/environment.yml\n","else:\n","     print('found', env_name, 'env', len(res))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\n","installing miniconda\n","--2020-11-26 22:25:59--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n","Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n","Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n","--2020-11-26 22:25:59--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n","Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n","Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 58468498 (56M) [application/x-sh]\n","Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n","\n","Miniconda3-4.5.4-Li 100%[===================>]  55.76M   259MB/s    in 0.2s    \n","\n","2020-11-26 22:25:59 (259 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n","\n","PREFIX=/usr/local\n","installing: python-3.6.5-hc3d631a_2 ...\n","Python 3.6.5 :: Anaconda, Inc.\n","installing: ca-certificates-2018.03.07-0 ...\n","installing: conda-env-2.6.0-h36134e3_1 ...\n","installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n","installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n","installing: libffi-3.2.1-hd88cf55_4 ...\n","installing: ncurses-6.1-hf484d3e_0 ...\n","installing: openssl-1.0.2o-h20670df_0 ...\n","installing: tk-8.6.7-hc745277_3 ...\n","installing: xz-5.2.4-h14c3975_4 ...\n","installing: yaml-0.1.7-had09818_2 ...\n","installing: zlib-1.2.11-ha838bed_2 ...\n","installing: libedit-3.1.20170329-h6b74fdf_2 ...\n","installing: readline-7.0-ha6073c6_4 ...\n","installing: sqlite-3.23.1-he433501_0 ...\n","installing: asn1crypto-0.24.0-py36_0 ...\n","installing: certifi-2018.4.16-py36_0 ...\n","installing: chardet-3.0.4-py36h0f667ec_1 ...\n","installing: idna-2.6-py36h82fb2a8_1 ...\n","installing: pycosat-0.6.3-py36h0a5515d_0 ...\n","installing: pycparser-2.18-py36hf9f622e_1 ...\n","installing: pysocks-1.6.8-py36_0 ...\n","installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n","installing: six-1.11.0-py36h372c433_1 ...\n","installing: cffi-1.11.5-py36h9745a5d_0 ...\n","installing: setuptools-39.2.0-py36_0 ...\n","installing: cryptography-2.2.2-py36h14c3975_0 ...\n","installing: wheel-0.31.1-py36_0 ...\n","installing: pip-10.0.1-py36_0 ...\n","installing: pyopenssl-18.0.0-py36_0 ...\n","installing: urllib3-1.22-py36hbe7ace6_0 ...\n","installing: requests-2.18.4-py36he2e5f8d_1 ...\n","installing: conda-4.5.4-py36_0 ...\n","installation finished.\n","WARNING:\n","    You currently have a PYTHONPATH environment variable set. This may cause\n","    unexpected behavior when running the Python interpreter in Miniconda3.\n","    For best results, please verify that your PYTHONPATH only points to\n","    directories of packages that are compatible with the Python interpreter\n","    in Miniconda3: /usr/local\n","Solving environment: ...working... done\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs: \n","    - conda\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    asn1crypto-1.4.0           |             py_0          77 KB\n","    chardet-3.0.4              |py37h06a4308_1003         173 KB\n","    tqdm-4.51.0                |     pyhd3eb1b0_0          66 KB\n","    idna-2.10                  |             py_0          56 KB\n","    wheel-0.35.1               |     pyhd3eb1b0_0          37 KB\n","    requests-2.24.0            |             py_0          54 KB\n","    pycosat-0.6.3              |   py37h27cfd23_0         108 KB\n","    pysocks-1.7.1              |           py37_1          27 KB\n","    python-3.7.0               |       hc3d631a_0        31.7 MB\n","    six-1.15.0                 |   py37h06a4308_0          27 KB\n","    ruamel_yaml-0.15.87        |   py37h7b6447c_1         253 KB\n","    openssl-1.0.2u             |       h7b6447c_0         3.1 MB\n","    urllib3-1.25.11            |             py_0          93 KB\n","    libedit-3.1.20181209       |       hc058e9b_0         188 KB\n","    yaml-0.2.5                 |       h7b6447c_0          87 KB\n","    zlib-1.2.11                |       h7b6447c_3         120 KB\n","    setuptools-50.3.1          |   py37h06a4308_1         901 KB\n","    ca-certificates-2020.10.14 |                0         128 KB\n","    cffi-1.14.0                |   py37h2e261b9_0         225 KB\n","    sqlite-3.31.1              |       h7b6447c_0         2.0 MB\n","    conda-package-handling-1.7.2|   py37h03888b9_0         977 KB\n","    readline-7.0               |       h7b6447c_5         392 KB\n","    pyopenssl-19.0.0           |           py37_0          82 KB\n","    cryptography-2.3.1         |   py37hc365091_0         585 KB\n","    brotlipy-0.7.0             |py37h27cfd23_1003         350 KB\n","    _libgcc_mutex-0.1          |             main           3 KB\n","    pycparser-2.20             |             py_2          94 KB\n","    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n","    tk-8.6.10                  |       hbc83047_0         3.2 MB\n","    certifi-2020.11.8          |   py37h06a4308_0         150 KB\n","    pip-20.2.4                 |   py37h06a4308_0         2.0 MB\n","    conda-4.9.2                |   py37h06a4308_0         3.1 MB\n","    xz-5.2.5                   |       h7b6447c_0         438 KB\n","    ------------------------------------------------------------\n","                                           Total:        58.7 MB\n","\n","The following NEW packages will be INSTALLED:\n","\n","    _libgcc_mutex:          0.1-main               \n","    brotlipy:               0.7.0-py37h27cfd23_1003\n","    conda-package-handling: 1.7.2-py37h03888b9_0   \n","    tqdm:                   4.51.0-pyhd3eb1b0_0    \n","\n","The following packages will be UPDATED:\n","\n","    asn1crypto:             0.24.0-py36_0           --> 1.4.0-py_0              \n","    ca-certificates:        2018.03.07-0            --> 2020.10.14-0            \n","    certifi:                2018.4.16-py36_0        --> 2020.11.8-py37h06a4308_0\n","    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.0-py37h2e261b9_0   \n","    chardet:                3.0.4-py36h0f667ec_1    --> 3.0.4-py37h06a4308_1003 \n","    conda:                  4.5.4-py36_0            --> 4.9.2-py37h06a4308_0    \n","    cryptography:           2.2.2-py36h14c3975_0    --> 2.3.1-py37hc365091_0    \n","    idna:                   2.6-py36h82fb2a8_1      --> 2.10-py_0               \n","    libedit:                3.1.20170329-h6b74fdf_2 --> 3.1.20181209-hc058e9b_0 \n","    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n","    openssl:                1.0.2o-h20670df_0       --> 1.0.2u-h7b6447c_0       \n","    pip:                    10.0.1-py36_0           --> 20.2.4-py37h06a4308_0   \n","    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py37h27cfd23_0    \n","    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2               \n","    pyopenssl:              18.0.0-py36_0           --> 19.0.0-py37_0           \n","    pysocks:                1.6.8-py36_0            --> 1.7.1-py37_1            \n","    python:                 3.6.5-hc3d631a_2        --> 3.7.0-hc3d631a_0        \n","    readline:               7.0-ha6073c6_4          --> 7.0-h7b6447c_5          \n","    requests:               2.18.4-py36he2e5f8d_1   --> 2.24.0-py_0             \n","    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.87-py37h7b6447c_1  \n","    setuptools:             39.2.0-py36_0           --> 50.3.1-py37h06a4308_1   \n","    six:                    1.11.0-py36h372c433_1   --> 1.15.0-py37h06a4308_0   \n","    sqlite:                 3.23.1-he433501_0       --> 3.31.1-h7b6447c_0       \n","    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0       \n","    urllib3:                1.22-py36hbe7ace6_0     --> 1.25.11-py_0            \n","    wheel:                  0.31.1-py36_0           --> 0.35.1-pyhd3eb1b0_0     \n","    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0        \n","    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n","    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3       \n","\n","Preparing transaction: ...working... done\n","Verifying transaction: ...working... done\n","Executing transaction: ...working... done\n","no change     /usr/local/condabin/conda\n","no change     /usr/local/bin/conda\n","no change     /usr/local/bin/conda-env\n","no change     /usr/local/bin/activate\n","no change     /usr/local/bin/deactivate\n","no change     /usr/local/etc/profile.d/conda.sh\n","no change     /usr/local/etc/fish/conf.d/conda.fish\n","no change     /usr/local/shell/condabin/Conda.psm1\n","no change     /usr/local/shell/condabin/conda-hook.ps1\n","no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n","no change     /usr/local/etc/profile.d/conda.csh\n","modified      /root/.bashrc\n","\n","==> For changes to take effect, close and re-open your current shell. <==\n","\n","Collecting package metadata (current_repodata.json): ...working... done\n","Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n","Collecting package metadata (repodata.json): ...working... done\n","Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n","\n","PackagesNotFoundError: The following packages are not available from current channels:\n","\n","  - _license\n","\n","Current channels:\n","\n","  - https://repo.anaconda.com/pkgs/main/linux-64\n","  - https://repo.anaconda.com/pkgs/main/noarch\n","  - https://repo.anaconda.com/pkgs/r/linux-64\n","  - https://repo.anaconda.com/pkgs/r/noarch\n","\n","To search for alternate channels that may provide the conda package you're\n","looking for, navigate to\n","\n","    https://anaconda.org\n","\n","and use the search bar at the top of the page.\n","\n","\n","not found finbert env 0\n","Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n","Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","\n","Downloading and Extracting Packages\n","fontconfig-2.13.0    | 291 KB    | : 100% 1.0/1 [00:00<00:00,  9.08it/s]\n","click-7.1.2          | 67 KB     | : 100% 1.0/1 [00:00<00:00, 27.32it/s]\n","readline-7.0         | 392 KB    | : 100% 1.0/1 [00:00<00:00,  7.55it/s]\n","joblib-0.17.0        | 205 KB    | : 100% 1.0/1 [00:00<00:00, 14.00it/s]\n","jupyter-1.0.0        | 6 KB      | : 100% 1.0/1 [00:00<00:00, 33.20it/s]\n","expat-2.2.10         | 192 KB    | : 100% 1.0/1 [00:00<00:00, 17.64it/s]\n","mkl-service-2.3.0    | 208 KB    | : 100% 1.0/1 [00:00<00:00, 16.78it/s]\n","defusedxml-0.6.0     | 23 KB     | : 100% 1.0/1 [00:00<00:00, 31.22it/s]\n","pygments-2.7.1       | 704 KB    | : 100% 1.0/1 [00:00<00:00,  5.80it/s]\n","pyzmq-19.0.2         | 499 KB    | : 100% 1.0/1 [00:00<00:00,  7.67it/s]\n","intel-openmp-2020.2  | 947 KB    | : 100% 1.0/1 [00:00<00:00,  6.24it/s]\n","numpy-1.16.3         | 49 KB     | : 100% 1.0/1 [00:00<00:00, 26.77it/s]\n","wheel-0.35.1         | 36 KB     | : 100% 1.0/1 [00:00<00:00, 26.67it/s]\n","pip-20.2.4           | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]\n","qtpy-1.9.0           | 39 KB     | : 100% 1.0/1 [00:00<00:00, 30.44it/s]\n","attrs-20.2.0         | 41 KB     | : 100% 1.0/1 [00:00<00:00, 26.89it/s]\n","jpeg-9b              | 247 KB    | : 100% 1.0/1 [00:00<00:00, 16.24it/s]\n","wcwidth-0.2.5        | 37 KB     | : 100% 1.0/1 [00:00<00:00, 24.38it/s]\n","nest-asyncio-1.4.1   | 10 KB     | : 100% 1.0/1 [00:00<00:00, 34.20it/s]\n","textblob-0.15.3      | 595 KB    | : 100% 1.0/1 [00:00<00:00,  8.54it/s]\n","tornado-6.0.4        | 649 KB    | : 100% 1.0/1 [00:00<00:00,  5.82it/s]\n","numpy-base-1.16.3    | 4.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.19it/s]\n","jupyter_client-6.1.7 | 76 KB     | : 100% 1.0/1 [00:00<00:00, 21.71it/s]\n","packaging-20.4       | 35 KB     | : 100% 1.0/1 [00:00<00:00, 29.11it/s]\n","cffi-1.14.3          | 224 KB    | : 100% 1.0/1 [00:00<00:00, 14.12it/s]\n","mistune-0.8.4        | 53 KB     | : 100% 1.0/1 [00:00<00:00, 21.74it/s]\n","freetype-2.10.4      | 901 KB    | : 100% 1.0/1 [00:00<00:00,  6.07it/s]\n","pytz-2020.1          | 239 KB    | : 100% 1.0/1 [00:00<00:00,  8.95it/s]\n","mkl_random-1.1.0     | 376 KB    | : 100% 1.0/1 [00:00<00:00,  9.23it/s]\n","pyqt-5.9.2           | 5.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.15s/it]\n","libstdcxx-ng-9.1.0   | 4.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.67it/s]\n","python-dateutil-2.8. | 224 KB    | : 100% 1.0/1 [00:00<00:00, 10.99it/s]\n","libsodium-1.0.18     | 387 KB    | : 100% 1.0/1 [00:00<00:00, 10.09it/s]\n","tk-8.6.10            | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.74it/s]\n","pandoc-2.11          | 12.5 MB   | : 100% 1.0/1 [00:02<00:00,  2.73s/it]\n","qtconsole-4.7.7      | 94 KB     | : 100% 1.0/1 [00:00<00:00, 16.93it/s]\n","xz-5.2.5             | 438 KB    | : 100% 1.0/1 [00:00<00:00,  7.91it/s]\n","argon2-cffi-20.1.0   | 49 KB     | : 100% 1.0/1 [00:00<00:00, 32.44it/s]\n","markupsafe-1.1.1     | 26 KB     | : 100% 1.0/1 [00:00<00:00, 36.95it/s]\n","entrypoints-0.3      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 30.24it/s]\n","certifi-2020.6.20    | 159 KB    | : 100% 1.0/1 [00:00<00:00, 23.33it/s]\n","ipywidgets-7.5.1     | 102 KB    | : 100% 1.0/1 [00:00<00:00, 17.13it/s]\n","terminado-0.9.1      | 26 KB     | : 100% 1.0/1 [00:00<00:00, 27.08it/s]\n","decorator-4.4.2      | 14 KB     | : 100% 1.0/1 [00:00<00:00, 27.13it/s]\n","jedi-0.17.2          | 950 KB    | : 100% 1.0/1 [00:00<00:00,  2.42it/s]\n","zeromq-4.3.3         | 678 KB    | : 100% 1.0/1 [00:00<00:00,  7.01it/s]\n","backcall-0.2.0       | 14 KB     | : 100% 1.0/1 [00:00<00:00, 36.98it/s]\n","pyrsistent-0.17.3    | 89 KB     | : 100% 1.0/1 [00:00<00:00, 15.42it/s]\n","mkl-2019.4           | 204.1 MB  | : 100% 1.0/1 [00:32<00:00, 32.40s/it]               \n","pyparsing-2.4.7      | 64 KB     | : 100% 1.0/1 [00:00<00:00, 24.31it/s]\n","ipykernel-5.1.3      | 168 KB    | : 100% 1.0/1 [00:00<00:00, 15.18it/s]\n","pickleshare-0.7.5    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 35.26it/s]\n","gst-plugins-base-1.1 | 6.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.16it/s]\n","testpath-0.4.4       | 88 KB     | : 100% 1.0/1 [00:00<00:00, 26.95it/s]\n","libgcc-ng-9.1.0      | 8.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.18s/it]\n","ptyprocess-0.6.0     | 23 KB     | : 100% 1.0/1 [00:00<00:00, 25.22it/s]\n","glib-2.56.2          | 5.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.17s/it]\n","ipython-7.18.1       | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.86it/s]\n","icu-58.2             | 22.7 MB   | : 100% 1.0/1 [00:03<00:00,  3.12s/it]\n","pandas-0.23.4        | 10.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.78s/it]               \n","openssl-1.1.1h       | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.77it/s]\n","importlib-metadata-2 | 35 KB     | : 100% 1.0/1 [00:00<00:00, 35.56it/s]\n","jinja2-2.11.2        | 97 KB     | : 100% 1.0/1 [00:00<00:00, 23.58it/s]\n","bleach-3.2.1         | 111 KB    | : 100% 1.0/1 [00:00<00:00, 20.83it/s]\n","ca-certificates-2020 | 128 KB    | : 100% 1.0/1 [00:00<00:00, 15.91it/s]\n","send2trash-1.5.0     | 16 KB     | : 100% 1.0/1 [00:00<00:00, 37.86it/s]\n","importlib_metadata-2 | 11 KB     | : 100% 1.0/1 [00:00<00:00, 39.76it/s]\n","libuuid-1.0.3        | 16 KB     | : 100% 1.0/1 [00:00<00:00, 43.75it/s]\n","ipython_genutils-0.2 | 39 KB     | : 100% 1.0/1 [00:00<00:00, 32.41it/s]\n","gstreamer-1.14.0     | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.75it/s]\n","jupyterlab_pygments- | 8 KB      | : 100% 1.0/1 [00:00<00:00, 41.33it/s]\n","notebook-6.1.4       | 6.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.20s/it]\n","widgetsnbextension-3 | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.83it/s]\n","jupyter_core-4.6.3   | 75 KB     | : 100% 1.0/1 [00:00<00:00, 22.44it/s]\n","tqdm-4.50.2          | 55 KB     | : 100% 1.0/1 [00:00<00:00, 21.06it/s]\n","setuptools-50.3.0    | 904 KB    | : 100% 1.0/1 [00:00<00:00,  4.40it/s]\n","pandocfilters-1.4.2  | 13 KB     | : 100% 1.0/1 [00:00<00:00, 30.41it/s]\n","dbus-1.13.18         | 586 KB    | : 100% 1.0/1 [00:00<00:00,  8.32it/s]\n","nbformat-5.0.8       | 101 KB    | : 100% 1.0/1 [00:00<00:00, 16.56it/s]\n","libxcb-1.14          | 610 KB    | : 100% 1.0/1 [00:00<00:00,  6.20it/s]\n","libffi-3.3           | 54 KB     | : 100% 1.0/1 [00:00<00:00, 28.19it/s]\n","libxml2-2.9.10       | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.17it/s]\n","qt-5.9.7             | 85.9 MB   | : 100% 1.0/1 [00:13<00:00, 13.44s/it]               \n","nbconvert-6.0.7      | 530 KB    | : 100% 1.0/1 [00:00<00:00,  7.03it/s]\n","sip-4.19.24          | 297 KB    | : 100% 1.0/1 [00:00<00:00, 16.29it/s]\n","prompt_toolkit-3.0.8 | 11 KB     | : 100% 1.0/1 [00:00<00:00, 27.37it/s]\n","six-1.15.0           | 13 KB     | : 100% 1.0/1 [00:00<00:00, 32.76it/s]\n","sqlite-3.33.0        | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.91it/s]\n","ncurses-6.2          | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.32it/s]\n","jupyter_console-6.2. | 26 KB     | : 100% 1.0/1 [00:00<00:00, 26.25it/s]\n","parso-0.7.0          | 71 KB     | : 100% 1.0/1 [00:00<00:00, 21.08it/s]\n","nltk-3.5             | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.55it/s]\n","libgfortran-ng-7.3.0 | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.09it/s]\n","libedit-3.1.20191231 | 121 KB    | : 100% 1.0/1 [00:00<00:00, 11.23it/s]\n","traitlets-5.0.5      | 81 KB     | : 100% 1.0/1 [00:00<00:00, 11.05it/s]\n","libpng-1.6.37        | 364 KB    | : 100% 1.0/1 [00:00<00:00, 11.46it/s]\n","webencodings-0.5.1   | 19 KB     | : 100% 1.0/1 [00:00<00:00, 38.61it/s]\n","python-3.7.3         | 36.7 MB   | : 100% 1.0/1 [00:04<00:00,  4.60s/it]               \n","nbclient-0.5.1       | 60 KB     | : 100% 1.0/1 [00:00<00:00, 19.30it/s]\n","regex-2020.10.15     | 358 KB    | : 100% 1.0/1 [00:00<00:00, 10.53it/s]\n","prompt-toolkit-3.0.8 | 244 KB    | : 100% 1.0/1 [00:00<00:00, 11.00it/s]\n","pcre-8.44            | 269 KB    | : 100% 1.0/1 [00:00<00:00, 12.32it/s]\n","async_generator-1.10 | 38 KB     | : 100% 1.0/1 [00:00<00:00, 13.92it/s]\n","jsonschema-3.2.0     | 45 KB     | : 100% 1.0/1 [00:00<00:00, 22.66it/s]\n","pycparser-2.20       | 94 KB     | : 100% 1.0/1 [00:00<00:00,  8.82it/s]\n","prometheus_client-0. | 48 KB     | : 100% 1.0/1 [00:00<00:00, 25.90it/s]\n","zlib-1.2.11          | 120 KB    | : 100% 1.0/1 [00:00<00:00, 13.68it/s]\n","pexpect-4.8.0        | 79 KB     | : 100% 1.0/1 [00:00<00:00, 15.78it/s]\n","zipp-3.3.1           | 11 KB     | : 100% 1.0/1 [00:00<00:00, 40.74it/s]\n","blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 47.50it/s]\n","mkl_fft-1.2.0        | 164 KB    | : 100% 1.0/1 [00:00<00:00, 16.94it/s]\n","Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n","['/usr/local/envs/finbert/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/finBERT/condaenv.0v7ft3l9.requirements.txt']\n","Pip subprocess output:\n","Collecting joblib==0.13.2\n","  Downloading joblib-0.13.2-py2.py3-none-any.whl (278 kB)\n","Collecting pytorch-pretrained-bert==0.6.2\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","Collecting scikit-learn==0.21.2\n","  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n","Collecting spacy==2.1.4\n","  Downloading spacy-2.1.4-cp37-cp37m-manylinux1_x86_64.whl (29.8 MB)\n","Collecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/envs/finbert/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 2)) (2020.10.15)\n","Collecting requests\n","  Downloading requests-2.25.0-py2.py3-none-any.whl (61 kB)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/envs/finbert/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 2)) (1.16.3)\n","Collecting boto3\n","  Downloading boto3-1.16.25-py2.py3-none-any.whl (129 kB)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/envs/finbert/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 2)) (4.50.2)\n","Collecting scipy>=0.17.0\n","  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n","Collecting srsly<1.1.0,>=0.0.5\n","  Downloading srsly-1.0.4-cp37-cp37m-manylinux2014_x86_64.whl (293 kB)\n","Collecting cymem<2.1.0,>=2.0.2\n","  Downloading cymem-2.0.4-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n","Collecting preshed<2.1.0,>=2.0.1\n","  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n","Collecting thinc<7.1.0,>=7.0.2\n","  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","Collecting blis<0.3.0,>=0.2.2\n","  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n","Collecting wasabi<1.1.0,>=0.2.0\n","  Downloading wasabi-0.8.0-py3-none-any.whl (23 kB)\n","Collecting plac<1.0.0,>=0.9.6\n","  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n","Collecting jsonschema<3.1.0,>=2.6.0\n","  Downloading jsonschema-3.0.2-py2.py3-none-any.whl (54 kB)\n","Collecting murmurhash<1.1.0,>=0.28.0\n","  Downloading murmurhash-1.0.4-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n","Collecting chardet<4,>=3.0.2\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/envs/finbert/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.6.2->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 2)) (2020.6.20)\n","Collecting idna<3,>=2.5\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","Collecting botocore<1.20.0,>=1.19.25\n","  Downloading botocore-1.19.25-py2.py3-none-any.whl (6.9 MB)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/envs/finbert/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy==2.1.4->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 4)) (0.17.3)\n","Requirement already satisfied, skipping upgrade: six>=1.11.0 in /usr/local/envs/finbert/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy==2.1.4->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 4)) (1.15.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/envs/finbert/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy==2.1.4->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 4)) (50.3.0.post20201006)\n","Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/envs/finbert/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy==2.1.4->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 4)) (20.2.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/finbert/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.25->boto3->pytorch-pretrained-bert==0.6.2->-r /content/finBERT/condaenv.0v7ft3l9.requirements.txt (line 2)) (2.8.1)\n","Installing collected packages: joblib, chardet, urllib3, idna, requests, torch, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, scipy, scikit-learn, srsly, cymem, preshed, blis, plac, wasabi, murmurhash, thinc, jsonschema, spacy\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 0.17.0\n","    Uninstalling joblib-0.17.0:\n","      Successfully uninstalled joblib-0.17.0\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 3.2.0\n","    Uninstalling jsonschema-3.2.0:\n","      Successfully uninstalled jsonschema-3.2.0\n","Successfully installed blis-0.2.4 boto3-1.16.25 botocore-1.19.25 chardet-3.0.4 cymem-2.0.4 idna-2.10 jmespath-0.10.0 joblib-0.13.2 jsonschema-3.0.2 murmurhash-1.0.4 plac-0.9.6 preshed-2.0.1 pytorch-pretrained-bert-0.6.2 requests-2.25.0 s3transfer-0.3.3 scikit-learn-0.21.2 scipy-1.5.4 spacy-2.1.4 srsly-1.0.4 thinc-7.0.8 torch-1.1.0 urllib3-1.26.2 wasabi-0.8.0\n","\n","\b\bdone\n","#\n","# To activate this environment, use\n","#\n","#     $ conda activate finbert\n","#\n","# To deactivate an active environment, use\n","#\n","#     $ conda deactivate\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Du3cmEWhYf5V","executionInfo":{"status":"ok","timestamp":1606429912637,"user_tz":300,"elapsed":355249,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"47b09f57-2514-48f4-cef0-0a6574a3b20f"},"source":["!which conda"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/bin/conda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEQ9i4f6YgA2","executionInfo":{"status":"ok","timestamp":1606429912838,"user_tz":300,"elapsed":355447,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"1934e5d4-7ed5-45ce-ba59-f46531d771bb"},"source":["!env"],"execution_count":5,"outputs":[{"output_type":"stream","text":["CUDNN_VERSION=7.6.5.32\n","__EGL_VENDOR_LIBRARY_DIRS=/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n","LD_LIBRARY_PATH=/usr/lib64-nvidia\n","CLOUDSDK_PYTHON=python3\n","LANG=en_US.UTF-8\n","HOSTNAME=11be4563287a\n","OLDPWD=/\n","CLOUDSDK_CONFIG=/content/.config\n","NVIDIA_VISIBLE_DEVICES=all\n","DATALAB_SETTINGS_OVERRIDES={\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"]}\n","ENV=/root/.bashrc\n","PAGER=cat\n","NCCL_VERSION=2.7.8\n","TF_FORCE_GPU_ALLOW_GROWTH=true\n","JPY_PARENT_PID=49\n","NO_GCE_CHECK=True\n","PWD=/content\n","HOME=/root\n","LAST_FORCED_REBUILD=20201111\n","CLICOLOR=1\n","DEBIAN_FRONTEND=noninteractive\n","LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n","GCE_METADATA_TIMEOUT=0\n","GLIBCPP_FORCE_NEW=1\n","TBE_CREDS_ADDR=172.28.0.1:8008\n","TERM=xterm-color\n","SHELL=/bin/bash\n","GCS_READ_CACHE_BLOCK_SIZE_MB=16\n","PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n","MPLBACKEND=module://ipykernel.pylab.backend_inline\n","CUDA_PKG_VERSION=10-1=10.1.243-1\n","CUDA_VERSION=10.1.243\n","NVIDIA_DRIVER_CAPABILITIES=compute,utility\n","SHLVL=1\n","PYTHONPATH=/env/python\n","NVIDIA_REQUIRE_CUDA=cuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n","COLAB_GPU=1\n","GLIBCXX_FORCE_NEW=1\n","PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n","LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n","GIT_PAGER=cat\n","_=/usr/bin/env\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nN_mx1YhYgJ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606429914888,"user_tz":300,"elapsed":357493,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"0aa852d9-5bb7-4e82-8c40-b96a91c0853f"},"source":["%%bash\n","source activate finbert\n","conda env list\n","conda list\n","python\n","import sys\n","\n","# maybe only need this the first time we run this notebook\n","sys.path.append('/usr/local/lib/python3.6/site-packages')\n","\n","print(\"Python version\")\n","print(sys.version)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["# conda environments:\n","#\n","base                     /usr/local\n","finbert               *  /usr/local/envs/finbert\n","\n","# packages in environment at /usr/local/envs/finbert:\n","#\n","# Name                    Version                   Build  Channel\n","argon2-cffi               20.1.0           py37h7b6447c_1    anaconda\n","async_generator           1.10             py37h28b3542_0    anaconda\n","attrs                     20.2.0                     py_0    anaconda\n","backcall                  0.2.0                      py_0    anaconda\n","blas                      1.0                         mkl    anaconda\n","bleach                    3.2.1                      py_0    anaconda\n","blis                      0.2.4                    pypi_0    pypi\n","boto3                     1.16.25                  pypi_0    pypi\n","botocore                  1.19.25                  pypi_0    pypi\n","ca-certificates           2020.10.14                    0    anaconda\n","certifi                   2020.6.20                py37_0    anaconda\n","cffi                      1.14.3           py37he30daa8_0    anaconda\n","chardet                   3.0.4                    pypi_0    pypi\n","click                     7.1.2                      py_0    anaconda\n","cymem                     2.0.4                    pypi_0    pypi\n","dbus                      1.13.18              hb2f20db_0    anaconda\n","decorator                 4.4.2                      py_0    anaconda\n","defusedxml                0.6.0                      py_0    anaconda\n","entrypoints               0.3                      py37_0    anaconda\n","expat                     2.2.10               he6710b0_2    anaconda\n","fontconfig                2.13.0               h9420a91_0    anaconda\n","freetype                  2.10.4               h5ab3b9f_0    anaconda\n","glib                      2.56.2               hd408876_0    anaconda\n","gst-plugins-base          1.14.0               hbbd80ab_1    anaconda\n","gstreamer                 1.14.0               hb453b48_1    anaconda\n","icu                       58.2                 he6710b0_3    anaconda\n","idna                      2.10                     pypi_0    pypi\n","importlib-metadata        2.0.0                      py_1    anaconda\n","importlib_metadata        2.0.0                         1    anaconda\n","intel-openmp              2020.2                      254    anaconda\n","ipykernel                 5.1.3            py37h39e3cac_1    anaconda\n","ipython                   7.18.1           py37h5ca1d4c_0    anaconda\n","ipython_genutils          0.2.0                    py37_0    anaconda\n","ipywidgets                7.5.1                      py_1    anaconda\n","jedi                      0.17.2                   py37_0    anaconda\n","jinja2                    2.11.2                     py_0    anaconda\n","jmespath                  0.10.0                   pypi_0    pypi\n","joblib                    0.13.2                   pypi_0    pypi\n","jpeg                      9b                   habf39ab_1    anaconda\n","jsonschema                3.0.2                    pypi_0    pypi\n","jupyter                   1.0.0                    py37_7    anaconda\n","jupyter_client            6.1.7                      py_0    anaconda\n","jupyter_console           6.2.0                      py_0    anaconda\n","jupyter_core              4.6.3                    py37_0    anaconda\n","jupyterlab_pygments       0.1.2                      py_0    anaconda\n","libedit                   3.1.20191231         h14c3975_1    anaconda\n","libffi                    3.3                  he6710b0_2    anaconda\n","libgcc-ng                 9.1.0                hdf63c60_0    anaconda\n","libgfortran-ng            7.3.0                hdf63c60_0    anaconda\n","libpng                    1.6.37               hbc83047_0    anaconda\n","libsodium                 1.0.18               h7b6447c_0    anaconda\n","libstdcxx-ng              9.1.0                hdf63c60_0    anaconda\n","libuuid                   1.0.3                h1bed415_2    anaconda\n","libxcb                    1.14                 h7b6447c_0    anaconda\n","libxml2                   2.9.10               hb55368b_3    anaconda\n","markupsafe                1.1.1            py37h14c3975_1    anaconda\n","mistune                   0.8.4           py37h14c3975_1001    anaconda\n","mkl                       2019.4                      243    anaconda\n","mkl-service               2.3.0            py37he904b0f_0    anaconda\n","mkl_fft                   1.2.0            py37h23d657b_0    anaconda\n","mkl_random                1.1.0            py37hd6b4f25_0    anaconda\n","murmurhash                1.0.4                    pypi_0    pypi\n","nbclient                  0.5.1                      py_0    anaconda\n","nbconvert                 6.0.7                    py37_0    anaconda\n","nbformat                  5.0.8                      py_0    anaconda\n","ncurses                   6.2                  he6710b0_1    anaconda\n","nest-asyncio              1.4.1                      py_0    anaconda\n","nltk                      3.5                        py_0    anaconda\n","notebook                  6.1.4                    py37_0    anaconda\n","numpy                     1.16.3           py37h7e9f1db_0    anaconda\n","numpy-base                1.16.3           py37hde5b4d6_0    anaconda\n","openssl                   1.1.1h               h7b6447c_0    anaconda\n","packaging                 20.4                       py_0    anaconda\n","pandas                    0.23.4           py37h04863e7_0    anaconda\n","pandoc                    2.11                 hb0f4dca_0    anaconda\n","pandocfilters             1.4.2                    py37_1    anaconda\n","parso                     0.7.0                      py_0    anaconda\n","pcre                      8.44                 he6710b0_0    anaconda\n","pexpect                   4.8.0                    py37_1    anaconda\n","pickleshare               0.7.5                 py37_1001    anaconda\n","pip                       20.2.4                   py37_0    anaconda\n","plac                      0.9.6                    pypi_0    pypi\n","preshed                   2.0.1                    pypi_0    pypi\n","prometheus_client         0.8.0                      py_0    anaconda\n","prompt-toolkit            3.0.8                      py_0    anaconda\n","prompt_toolkit            3.0.8                         0    anaconda\n","ptyprocess                0.6.0                    py37_0    anaconda\n","pycparser                 2.20                       py_2    anaconda\n","pygments                  2.7.1                      py_0    anaconda\n","pyparsing                 2.4.7                      py_0    anaconda\n","pyqt                      5.9.2            py37h22d08a2_1    anaconda\n","pyrsistent                0.17.3           py37h7b6447c_0    anaconda\n","python                    3.7.3                h0371630_0    anaconda\n","python-dateutil           2.8.1                      py_0    anaconda\n","pytorch-pretrained-bert   0.6.2                    pypi_0    pypi\n","pytz                      2020.1                     py_0    anaconda\n","pyzmq                     19.0.2           py37he6710b0_1    anaconda\n","qt                        5.9.7                h5867ecd_1    anaconda\n","qtconsole                 4.7.7                      py_0    anaconda\n","qtpy                      1.9.0                      py_0    anaconda\n","readline                  7.0                  h7b6447c_5    anaconda\n","regex                     2020.10.15       py37h7b6447c_0    anaconda\n","requests                  2.25.0                   pypi_0    pypi\n","s3transfer                0.3.3                    pypi_0    pypi\n","scikit-learn              0.21.2                   pypi_0    pypi\n","scipy                     1.5.4                    pypi_0    pypi\n","send2trash                1.5.0                    py37_0    anaconda\n","setuptools                50.3.0           py37hb0f4dca_1    anaconda\n","sip                       4.19.24          py37he6710b0_0    anaconda\n","six                       1.15.0                     py_0    anaconda\n","spacy                     2.1.4                    pypi_0    pypi\n","sqlite                    3.33.0               h62c20be_0    anaconda\n","srsly                     1.0.4                    pypi_0    pypi\n","terminado                 0.9.1                    py37_0    anaconda\n","testpath                  0.4.4                      py_0    anaconda\n","textblob                  0.15.3                     py_0    conda-forge\n","thinc                     7.0.8                    pypi_0    pypi\n","tk                        8.6.10               hbc83047_0    anaconda\n","torch                     1.1.0                    pypi_0    pypi\n","tornado                   6.0.4            py37h7b6447c_1    anaconda\n","tqdm                      4.50.2                     py_0    anaconda\n","traitlets                 5.0.5                      py_0    anaconda\n","urllib3                   1.26.2                   pypi_0    pypi\n","wasabi                    0.8.0                    pypi_0    pypi\n","wcwidth                   0.2.5                      py_0    anaconda\n","webencodings              0.5.1                    py37_1    anaconda\n","wheel                     0.35.1                     py_0    anaconda\n","widgetsnbextension        3.5.1                    py37_0    anaconda\n","xz                        5.2.5                h7b6447c_0    anaconda\n","zeromq                    4.3.3                he6710b0_3    anaconda\n","zipp                      3.3.1                      py_0    anaconda\n","zlib                      1.2.11               h7b6447c_3    anaconda\n","Python version\n","3.7.3 (default, Mar 27 2019, 22:11:17) \n","[GCC 7.3.0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oi9Z9Lsjxl19"},"source":["## Download pre-trained model and prep project folder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"FGFJNjtDxi69","executionInfo":{"status":"ok","timestamp":1606429941745,"user_tz":300,"elapsed":384348,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"cb88a412-0212-4e14-f254-60ec3f2f852f"},"source":["import os\n","from shutil import copyfile\n","\n","lm_path = finBERT_repo_path + '/models/language_model/finbertTRC2'\n","cl_path = finBERT_repo_path + '/models/classifier_model/finbert-sentiment'\n","cl_data_path = finBERT_repo_path + '/data/sentiment_data'\n","\n","# Clean the cl_path\n","try:\n","    shutil.rmtree(cl_path) \n","    shutil.rmtree(lm_path) \n","except:\n","    pass\n","\n","for p in [lm_path, cl_path, cl_data_path]:\n","  if not os.path.exists(p):\n","    os.makedirs(p)\n","\n","lm_model_link = 'https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/language-model/pytorch_model.bin'\n","cl_model_link = 'https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/finbert-sentiment/pytorch_model.bin'\n","!wget $lm_model_link -P $lm_path\n","!wget $cl_model_link -P $cl_path\n","\n","src = os.path.join(finBERT_repo_path, 'config.json')\n","dst = os.path.join(cl_path, 'config.json')\n","copyfile(src, dst)\n","\n","dst = os.path.join(lm_path, 'config.json')\n","copyfile(src, dst)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2020-11-26 22:31:55--  https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/language-model/pytorch_model.bin\n","Resolving prosus-public.s3-eu-west-1.amazonaws.com (prosus-public.s3-eu-west-1.amazonaws.com)... 52.218.37.200\n","Connecting to prosus-public.s3-eu-west-1.amazonaws.com (prosus-public.s3-eu-west-1.amazonaws.com)|52.218.37.200|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 440477289 (420M) [application/octet-stream]\n","Saving to: ‘/content/finBERT/models/language_model/finbertTRC2/pytorch_model.bin’\n","\n","pytorch_model.bin   100%[===================>] 420.07M  34.3MB/s    in 13s     \n","\n","2020-11-26 22:32:08 (32.5 MB/s) - ‘/content/finBERT/models/language_model/finbertTRC2/pytorch_model.bin’ saved [440477289/440477289]\n","\n","--2020-11-26 22:32:08--  https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/finbert-sentiment/pytorch_model.bin\n","Resolving prosus-public.s3-eu-west-1.amazonaws.com (prosus-public.s3-eu-west-1.amazonaws.com)... 52.218.89.24\n","Connecting to prosus-public.s3-eu-west-1.amazonaws.com (prosus-public.s3-eu-west-1.amazonaws.com)|52.218.89.24|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 437988463 (418M) [application/octet-stream]\n","Saving to: ‘/content/finBERT/models/classifier_model/finbert-sentiment/pytorch_model.bin’\n","\n","pytorch_model.bin   100%[===================>] 417.70M  34.8MB/s    in 13s     \n","\n","2020-11-26 22:32:21 (33.0 MB/s) - ‘/content/finBERT/models/classifier_model/finbert-sentiment/pytorch_model.bin’ saved [437988463/437988463]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/finBERT/models/language_model/finbertTRC2/config.json'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"xmqEqjMRbgjg"},"source":["# Predict Method 1\n","\n","Follow this notebook -> https://github.com/ProsusAI/finBERT/blob/master/notebooks/finbert_training.ipynb\n","\n","Because of the conda environment dependencies the cell needs to be running as a shell script hence the \" %%bash \" line. \n","\n","All python code is runnable after the line \"python\" in the cell/shell script"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sv9WoY_Fbnnv","executionInfo":{"status":"ok","timestamp":1606429955886,"user_tz":300,"elapsed":398485,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"a22f2891-3af9-42e9-edb2-937469863084"},"source":["%%bash\n","source activate finbert\n","conda env list\n","cd /content/finBERT/\n","\n","python \n","# python code starts here\n","from pathlib import Path\n","import sys\n","sys.path.append('..')\n","import argparse\n","import shutil\n","import os\n","import logging\n","from textblob import TextBlob\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n","from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import *\n","\n","from finbert.finbert import *\n","import finbert.utils as tools\n","from pprint import pprint\n","from sklearn.metrics import classification_report\n","\n","project_dir = Path.cwd()\n","print(project_dir)\n","# finBERT_repo_path = '/content/finBERT'\n","\n","pd.set_option('max_colwidth', -1)\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.ERROR)\n","\n","lm_path = project_dir/'models'/'language_model'/'finbertTRC2'\n","cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n","cl_data_path = project_dir/'data'/'sentiment_data'\n","\n","text = \"Later that day Apple said it was revising down its earnings expectations in \\\n","the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. \\\n","The news rapidly infected financial markets. Apple’s share price fell by around 7% in after-hours \\\n","trading and the decline was extended to more than 10% when the market opened. The dollar fell \\\n","by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering \\\n","some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. \\\n","Yields on government bonds fell as investors fled to the traditional haven in a market storm.\"\n","\n","text2 = \"Shares in the spin-off of South African e-commerce group Naspers surged more than 25% \\\n","in the first minutes of their market debut in Amsterdam on Wednesday. Bob van Dijk, CEO of \\\n","Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the \\\n","Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019. REUTERS/Piroschka van de Wouw \\\n","Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a \\\n","31% stake in Chinese tech titan Tencent. There is 'way more demand than is even available, so that’s \\\n","good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg. 'It’s going to be an interesting \\\n","hour of trade after opening this morning.' Euronext had given an indicative price of 58.70 euros \\\n","per share for Prosus, implying a market value of 95.3 billion euros ($105 billion). The shares \\\n","jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.\"\n","\n","## cl_model\n","\n","model = BertForSequenceClassification.from_pretrained(cl_path,cache_dir=True, num_labels=3)\n","\n","result = predict(text,model)\n","blob = TextBlob(text)\n","result['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n","print(result)\n","print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))\n","\n","result2 = predict(text2,model)\n","blob = TextBlob(text2)\n","result2['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n","print(result2)\n","print(f'Average sentiment is %.2f.' % (result2.sentiment_score.mean()))\n","\n","## TRC model predict\n","\n","model = BertForSequenceClassification.from_pretrained(lm_path, cache_dir=True, num_labels=3)\n","\n","result = predict(text,model)\n","blob = TextBlob(text)\n","result['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n","print(result)\n","print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))\n","\n","result2 = predict(text2,model)\n","blob = TextBlob(text2)\n","result2['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n","print(result2)\n","print(f'Average sentiment is %.2f.' % (result2.sentiment_score.mean()))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["# conda environments:\n","#\n","base                     /usr/local\n","finbert               *  /usr/local/envs/finbert\n","\n","/content/finBERT\n","                                                                                                                                                                          sentence         ...         textblob_prediction\n","0  Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.         ...          0.051746          \n","1  The news rapidly infected financial markets.                                                                                                                                            ...          0.000000          \n","2  Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.                                                      ...          0.500000          \n","3  The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.                                                           ...          0.000000          \n","4  Asian stockmarkets closed down on January 3rd and European ones opened lower.                                                                                                           ...         -0.051111          \n","5  Yields on government bonds fell as investors fled to the traditional haven in a market storm.                                                                                           ...          0.000000          \n","\n","[6 rows x 5 columns]\n","Average sentiment is -0.91.\n","                                                                                                                                                                                    sentence         ...         textblob_prediction\n","0  Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.                                       ...          0.250000          \n","1  Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.         ...          0.000000          \n","2  REUTERS/Piroschka van de Wouw Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.                         ...          0.000000          \n","3  There is 'way more demand than is even available, so that’s good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.                                                                       ...          0.533333          \n","4  'It’s going to be an interesting hour of trade after opening this morning.'                                                                                                                       ...          0.500000          \n","5  Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).                                                         ...          0.000000          \n","6  The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.                                                                                                                ...          0.000000          \n","\n","[7 rows x 5 columns]\n","Average sentiment is 0.44.\n","                                                                                                                                                                          sentence         ...         textblob_prediction\n","0  Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.         ...          0.051746          \n","1  The news rapidly infected financial markets.                                                                                                                                            ...          0.000000          \n","2  Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.                                                      ...          0.500000          \n","3  The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.                                                           ...          0.000000          \n","4  Asian stockmarkets closed down on January 3rd and European ones opened lower.                                                                                                           ...         -0.051111          \n","5  Yields on government bonds fell as investors fled to the traditional haven in a market storm.                                                                                           ...          0.000000          \n","\n","[6 rows x 5 columns]\n","Average sentiment is 0.15.\n","                                                                                                                                                                                    sentence         ...         textblob_prediction\n","0  Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.                                       ...          0.250000          \n","1  Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.         ...          0.000000          \n","2  REUTERS/Piroschka van de Wouw Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.                         ...          0.000000          \n","3  There is 'way more demand than is even available, so that’s good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.                                                                       ...          0.533333          \n","4  'It’s going to be an interesting hour of trade after opening this morning.'                                                                                                                       ...          0.500000          \n","5  Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).                                                         ...          0.000000          \n","6  The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.                                                                                                                ...          0.000000          \n","\n","[7 rows x 5 columns]\n","Average sentiment is 0.14.\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","11/26/2020 22:32:24 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/finBERT/models/classifier_model/finbert-sentiment from cache at /content/finBERT/models/classifier_model/finbert-sentiment\n","11/26/2020 22:32:24 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","11/26/2020 22:32:27 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp0s039qoj\n","\r  0%|          | 0/231508 [00:00<?, ?B/s]\r100%|██████████| 231508/231508 [00:00<00:00, 25227064.26B/s]\n","11/26/2020 22:32:27 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp0s039qoj to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:27 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:27 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp0s039qoj\n","11/26/2020 22:32:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:27 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:27 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:27 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n","11/26/2020 22:32:27 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:27 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:27 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:27 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:28 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:28 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:28 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n","11/26/2020 22:32:28 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:28 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:28 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:28 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:29 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:29 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:29 - INFO - finbert.utils -   tokens: [CLS] shares in the spin - off of south african e - commerce group nas ##pers surged more than 25 % in the first minutes of their market debut in amsterdam on wednesday . [SEP]\n","11/26/2020 22:32:29 - INFO - finbert.utils -   input_ids: 101 6661 1999 1996 6714 1011 2125 1997 2148 3060 1041 1011 6236 2177 17235 7347 18852 2062 2084 2423 1003 1999 1996 2034 2781 1997 2037 3006 2834 1999 7598 2006 9317 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:29 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:29 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:29 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:30 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:30 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:30 - INFO - finbert.utils -   tokens: [CLS] euro ##ne ##xt had given an indicative price of 58 . 70 euros per share for pro ##sus , implying a market value of 95 . 3 billion euros ( $ 105 billion ) . [SEP]\n","11/26/2020 22:32:30 - INFO - finbert.utils -   input_ids: 101 9944 2638 18413 2018 2445 2019 24668 3976 1997 5388 1012 3963 19329 2566 3745 2005 4013 13203 1010 20242 1037 3006 3643 1997 5345 1012 1017 4551 19329 1006 1002 8746 4551 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:30 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:30 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:30 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:30 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/finBERT/models/language_model/finbertTRC2 from cache at /content/finBERT/models/language_model/finbertTRC2\n","11/26/2020 22:32:30 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","11/26/2020 22:32:33 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","11/26/2020 22:32:33 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","11/26/2020 22:32:33 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:33 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:33 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:33 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n","11/26/2020 22:32:33 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:33 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:33 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:33 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:34 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:34 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n","11/26/2020 22:32:34 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:34 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:34 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   tokens: [CLS] shares in the spin - off of south african e - commerce group nas ##pers surged more than 25 % in the first minutes of their market debut in amsterdam on wednesday . [SEP]\n","11/26/2020 22:32:34 - INFO - finbert.utils -   input_ids: 101 6661 1999 1996 6714 1011 2125 1997 2148 3060 1041 1011 6236 2177 17235 7347 18852 2062 2084 2423 1003 1999 1996 2034 2781 1997 2037 3006 2834 1999 7598 2006 9317 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:34 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:35 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:35 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:35 - INFO - finbert.utils -   tokens: [CLS] euro ##ne ##xt had given an indicative price of 58 . 70 euros per share for pro ##sus , implying a market value of 95 . 3 billion euros ( $ 105 billion ) . [SEP]\n","11/26/2020 22:32:35 - INFO - finbert.utils -   input_ids: 101 9944 2638 18413 2018 2445 2019 24668 3976 1997 5388 1012 3963 19329 2566 3745 2005 4013 13203 1010 20242 1037 3006 3643 1997 5345 1012 1017 4551 19329 1006 1002 8746 4551 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:35 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:35 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:35 - INFO - finbert.utils -   label: None (id = 9090)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"VSQwpM3TY_zX"},"source":["# Financial News Web Scraper 1\n","\n","following: https://towardsdatascience.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638\n"]},{"cell_type":"code","metadata":{"id":"FBKM2bIGZJYM","executionInfo":{"status":"ok","timestamp":1606429956186,"user_tz":300,"elapsed":398782,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}}},"source":["# Import libraries\n","from urllib.request import urlopen, Request\n","from bs4 import BeautifulSoup\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","finwiz_url = 'https://finviz.com/quote.ashx?t='"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"95jGVqNhZWsK","executionInfo":{"status":"ok","timestamp":1606429959112,"user_tz":300,"elapsed":401706,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}}},"source":["news_tables = {}\n","tickers = ['AMZN', 'TSLA', 'GOOG']\n","\n","for ticker in tickers:\n","    url = finwiz_url + ticker\n","    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n","    response = urlopen(req)    \n","    # Read the contents of the file into 'html'\n","    html = BeautifulSoup(response)\n","    # Find 'news-table' in the Soup and load it into 'news_table'\n","    news_table = html.find(id='news-table')\n","    # Add the table to our dictionary\n","    news_tables[ticker] = news_table"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5OOaaiHZXkr","executionInfo":{"status":"ok","timestamp":1606429959114,"user_tz":300,"elapsed":401704,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"07fd6cbe-35af-475d-f8e4-b2aadf1d441c"},"source":["# Read one single day of headlines for 'AMZN' \n","amzn = news_tables['AMZN']\n","# Get all the table rows tagged in HTML with <tr> into 'amzn_tr'\n","amzn_tr = amzn.findAll('tr')\n","\n","for i, table_row in enumerate(amzn_tr):\n","    # Read the text of the element 'a' into 'link_text'\n","    a_text = table_row.a.text\n","    # Read the text of the element 'td' into 'data_text'\n","    td_text = table_row.td.text\n","    # Print the contents of 'link_text' and 'data_text' \n","    print(a_text)\n","    print(td_text)\n","    # Exit after printing 4 rows of data\n","    if i == 3:\n","        break"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Amazon spends $500m on bonuses for Christmas staff\n","Nov-26-20 04:52PM  \n","The Amazon of Africa is trying to enable third-party e-commerce rather than sell more stuff\n","03:27PM  \n","Amazon to give $500 million in holiday bonuses to front-line U.S. workers\n","01:12PM  \n","Amazon to give $500 million in holiday bonuses to front-line U.S. workers\n","01:05PM  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOir7SjhZedd","executionInfo":{"status":"ok","timestamp":1606429959116,"user_tz":300,"elapsed":401704,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"548b89c7-f022-4230-cbb8-6b04679758ff"},"source":["parsed_news = []\n","\n","# Iterate through the news\n","for file_name, news_table in news_tables.items():\n","    # Iterate through all tr tags in 'news_table'\n","    for x in news_table.findAll('tr'):\n","        # read the text from each tr tag into text\n","        # get text from a only\n","        text = x.a.get_text() \n","        # splite text in the td tag into a list \n","        date_scrape = x.td.text.split()\n","        # if the length of 'date_scrape' is 1, load 'time' as the only element\n","\n","        if len(date_scrape) == 1:\n","            time = date_scrape[0]\n","            \n","        # else load 'date' as the 1st element and 'time' as the second    \n","        else:\n","            date = date_scrape[0]\n","            time = date_scrape[1]\n","        # Extract the ticker from the file name, get the string up to the 1st '_'  \n","        ticker = file_name.split('_')[0]\n","        \n","        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n","        parsed_news.append([ticker, date, time, text])\n","        \n","parsed_news"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['AMZN',\n","  'Nov-26-20',\n","  '04:52PM',\n","  'Amazon spends $500m on bonuses for Christmas staff'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '03:27PM',\n","  'The Amazon of Africa is trying to enable third-party e-commerce rather than sell more stuff'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '01:12PM',\n","  'Amazon to give $500 million in holiday bonuses to front-line U.S. workers'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '01:05PM',\n","  'Amazon to give $500 million in holiday bonuses to front-line U.S. workers'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '11:00AM',\n","  \"Here's the Critically Important Point Investors Missed About Amazon's Earnings\"],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '08:59AM',\n","  'How XOUT Capital Picks Retailers for Its Large-Cap Index Fund'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '07:15AM',\n","  '3 Top E-Commerce Stocks to Buy Ahead of Blockbuster Black Friday Sales'],\n"," ['AMZN', 'Nov-26-20', '07:01AM', '3 Index Funds Perfect for Your IRA'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '07:00AM',\n","  '10 Stocks to Be Thankful for This Thanksgiving'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '06:19AM',\n","  'Even Amazon Is as Cheap as a Penny Stock -- With Fractional Shares'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '06:00AM',\n","  'The S&P 500 Could Jump 20% Next Year. Three Strategists Explain Why.'],\n"," ['AMZN', 'Nov-26-20', '05:51AM', '5 Perfect Stocks to Gobble Up Right Now'],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '04:23AM',\n","  \"Amazon's cloud service back up after widespread outage\"],\n"," ['AMZN',\n","  'Nov-26-20',\n","  '01:00AM',\n","  'Forget the Bargain Basement. Bet on the Next Big Thing'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:09PM',\n","  'These 2 IPO Stocks Are Crushing the Stock Market on Wednesday'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '05:34PM',\n","  \"Amazon workers in Germany to go on strike on 'Black Friday'\"],\n"," ['AMZN', 'Nov-25-20', '05:34PM', 'Affirm Deep Dive'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '05:30PM',\n","  'Amazon workers in Germany to go on strike on \"Black Friday\"'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '04:25PM',\n","  'A Stock Traders Guide to Black Friday in the Covid-19 Era'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '04:03PM',\n","  'GM Vs. Ford: 5 Reasons Why One Is Pulling Ahead On Electric Cars'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '03:36PM',\n","  'Gift Guide: 7 smart home gift ideas that go beyond the usual Google/Amazon smart speakers'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '02:50PM',\n","  'Amazon Cloud Outage Hits Customers Including Roku, Adobe'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '02:29PM',\n","  'Amazons AWS Was Hit by Outages. What You Need to Know.'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '02:24PM',\n","  'Amazon Web Services Outage Disrupts Internet'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:29PM',\n","  'The Zacks Analyst Blog Highlights: Alibaba and Amazon'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:19PM',\n","  'Salesforce acquisition of Slack could trigger M&A wave, analyst says'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:08PM',\n","  'TV shows you should binge watch this holiday weekend'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:59PM',\n","  'Coronavirus surge and no stimulus will result in empty storefronts nationwide'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:50PM',\n","  'Black Friday Will Be Great for Shoppers. It Wont Matter Much for Retail Stocks.'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:49PM',\n","  'ViacomCBS Is Selling Its Book Publisher for $2.2 Billion. What It Means for the Stock.'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:32PM',\n","  'Amazon Web Services outage takes a portion of the internet down with it'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:26PM',\n","  'Amazon Web Services suffers amid widespread issues with online applications'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:24PM',\n","  \"Amazon's (AMZN) AWS Adds Amazon MWAA to Services Portfolio\"],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '12:13PM',\n","  'Anaplan (PLAN) Q3 Loss Narrower than Expected, Revenues Up Y/Y'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '11:53AM',\n","  'Amazon Merchants Say Deliveries of Some Products Are Delayed'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '11:51AM',\n","  'Mastercard retail advisor on holiday shopping: Its all about making consumers feel safe this year'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '11:34AM',\n","  'How much people are expected to spend this Cyber Monday'],\n"," ['AMZN', 'Nov-25-20', '10:45AM', 'Better Buy: Alibaba vs. Amazon'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '09:43AM',\n","  'IBM Planning 10,000 Job Cuts in Europe Ahead of Unit Sale'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '09:21AM',\n","  'HP CEO: COVID-19 pandemic has reinforced our consumer business'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '09:16AM',\n","  'Orange (ORAN) Teams Up With Amazon to Optimize AWS Apps'],\n"," ['AMZN', 'Nov-25-20', '09:00AM', '2 Top Stocks You Can Buy On Sale'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '08:45AM',\n","  'The 3 Largest Retail Apocalypse-Proof Stocks in 2020'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '08:39AM',\n","  'Colin Kaepernick will not play in the NFL again: Emmanuel Acho'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '08:15AM',\n","  'France defies U.S. and starts levying digital tax on tech giants. But will this change with a Biden presidency?'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '07:30AM',\n","  'Hedge Funds Are Finally Beating the Market in 2020. Here Are Their Top Holdings.'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '07:18AM',\n","  '3 Growth Stocks to Buy and Hold for the Next 50 Years'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '07:16AM',\n","  'French tax authorities have started demanding U.S. firms pay digital tax: report'],\n"," ['AMZN', 'Nov-25-20', '06:55AM', \"Is BJ's Wholesale Club Stock a Buy?\"],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:54AM',\n","  \"Amazon Canada's First SMB Impact Report Highlights Success for Small and Medium-Sized Businesses; Canadian Sellers Grossed more than $2 Billion on Amazon's Stores Around the World\"],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:36AM',\n","  'Amazon Launches IP Accelerator in Europe to Help Small Businesses Protect Their Brands and Tackle Counterfeit'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:33AM',\n","  'Amazon (AMZN) Cloud Clientele Improves as Zalando Picks AWS'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:30AM',\n","  'Equal-Weighted Indexes Are Winningand Thats a Good Sign for Stocks'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '06:00AM',\n","  'Why GoodRxs CEO Isnt Worried About Amazon Pharmacy'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '05:32AM',\n","  'Big Brother Amazon Targeted in Retail Fight With Ambani'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '04:01AM',\n","  'French Tax Authorities Nudge Amazon, Facebook To Shell Out Digital Tax: FT'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '02:36AM',\n","  \"eBay's Seller-Poaching Allegations Against Amazon Get Dismissed By Arbitration Panel\"],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:33AM',\n","  \"India's NSE warned Future Retail of action over disclosures on Amazon dispute: emails\"],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:30AM',\n","  'South Korea Unveils AI Chip to Maintain Semiconductor Leadership'],\n"," ['AMZN',\n","  'Nov-25-20',\n","  '01:13AM',\n","  \"India's NSE warned Future Retail of action over disclosures on Amazon dispute -emails\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '10:36PM',\n","  'Venture Capitalists Discuss the Future of Gaming'],\n"," ['AMZN', 'Nov-24-20', '06:09PM', 'Airbnb Prepares to IPO'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '04:28PM',\n","  'Amazon Joins Feds on Anticounterfeit Strike Force'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '04:27PM',\n","  'Dell Reports Revenue That Tops Estimates on Robust PC Demand'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '04:24PM',\n","  'FedEx Stock, IBD Stock Of The Day, Breaks Out Ahead Of Holiday Surge'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '03:53PM',\n","  'AWS Announces General Availability of Amazon Managed Workflows for Apache Airflow'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '01:31PM',\n","  'Retailers Have No Idea What Will Happen This Holiday Season'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '01:25PM',\n","  \"Cramer's Year-End Game Plan: Load Up On Digital Retailers\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '01:08PM',\n","  'Is Amazon.com, Inc. (AMZN) A Good Stock To Buy According To Hedge Funds?'],\n"," ['AMZN', 'Nov-24-20', '12:45PM', 'Better Buy: Shopify vs. Wayfair'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '12:04PM',\n","  \"Macy's, Target, Gap and Best Buy  are part of Zacks Earnings Preview\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '11:58AM',\n","  \"Newell's Sunbeam recalls over 900,000 Crock-Pot multi-cookers due to burn hazard\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '11:18AM',\n","  'Walmart Stock Performance Has Doubled That of the S&P 500 Since Doing This One Thing'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '10:49AM',\n","  'Black Friday 2020: Retail winners and losers'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '10:34AM',\n","  '2 E-Commerce Stocks That Are Outperforming Amazon'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '10:31AM',\n","  \"Amazon's (AMZN) New Features to Ensure Spoil-Free Holiday Season\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '09:25AM',\n","  'Amazons $3,000 Signing Bonuses Irk Workers Who Got\\xa0$10 Coupons'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '08:41AM',\n","  \"What to Make of NVIDIA's Latest Earnings Report\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '08:00AM',\n","  \"Is This Weight Loss Company Coming for WW And Noom's Market Share?\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '08:00AM',\n","  'IPR Center, Amazon Launch Operation Fulfilled Action to Stop Counterfeits'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '07:49AM',\n","  'Best Buy is latest big retailer to shock everyone by its sales growth during COVID-19'],\n"," ['AMZN', 'Nov-24-20', '07:07AM', 'Netflix in 3 Charts'],\n"," ['AMZN', 'Nov-24-20', '07:00AM', 'Dont Overlook Sales at These 9 Retailers'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '07:00AM',\n","  'Amazon Brings Computer Science Education to the Home Classroom with the Cyber Robotics Challenge'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '06:30AM',\n","  \"Microsoft's Cloud Growth Continues to Pay Dividends\"],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '05:51AM',\n","  '4 Robinhood Stocks Billionaires Bought in Q3'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '04:17AM',\n","  'What the Vaccine News Means for Airline Stocks'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '03:01AM',\n","  'Zalando Selects AWS as Its Preferred Cloud Provider'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '03:01AM',\n","  'Mercado Libre Selects AWS as Its Primary Cloud Provider to Accelerate Growth and Transformation into a Data-Driven Company'],\n"," ['AMZN',\n","  'Nov-24-20',\n","  '02:19AM',\n","  \"We're Better Off Without the Black Friday Frenzy\"],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '10:45PM',\n","  'Amazon Warehouse Workers in Alabama Petition to Form a Union'],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '10:26PM',\n","  \"Coronavirus: Retail workers 'scared' as cases surge\"],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '10:07PM',\n","  \"Amazon's Answer To Apple AirPods, The Echo Buds, Can Now Track Workouts\"],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '06:14PM',\n","  'Walmart, Amazon Workers Seek Pandemic Hazard Pay'],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '05:28PM',\n","  'How Thanksgiving and Black Friday Affect Stocks'],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '02:35PM',\n","  'Why Plug Power, Bloom Energy, and Clean Energy Fuels Stocks Popped Monday'],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '02:27PM',\n","  'Black Friday 2020 will be a smaller event as retailers spread promotions across the holiday season'],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '01:21PM',\n","  \"Party City CEO: It's all about the balloons this holiday season\"],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '01:18PM',\n","  \"Why CEOs Are Uniting Against Trump's Election Fight\"],\n"," ['AMZN',\n","  'Nov-23-20',\n","  '01:04PM',\n","  '7 Most Profitable Businesses With Least Investment in 2020'],\n"," ['TSLA',\n","  'Nov-26-20',\n","  '12:09PM',\n","  'Dow Jones, Nasdaq Hit Highs Amid Coronavirus News As Tesla, Nio, Boeing Rally; Salesforce-Slack Deal Near?'],\n"," ['TSLA',\n","  'Nov-26-20',\n","  '08:05AM',\n","  'Tesla (TSLA) Recalls More Than 9,500 SUVs on Safety Concerns'],\n"," ['TSLA',\n","  'Nov-26-20',\n","  '06:15AM',\n","  \"These 3 Stocks Took Off During Trump's Presidency. Are They Still Good Buys Today?\"],\n"," ['TSLA',\n","  'Nov-26-20',\n","  '01:00AM',\n","  'Forget the Bargain Basement. Bet on the Next Big Thing'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:37PM',\n","  'Dow Jones Slips 173 Points After Hitting 30,000; Nasdaq Leads Market'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:30PM',\n","  'Tesla Stock Rises Again, Creating Another Problem for Index Funds'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:13PM',\n","  'US STOCKS-S&P 500, Dow pull back from all-time closing highs after grim jobless data'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:11PM',\n","  'Stock market news live updates: Wall Street catches breath after Dow hits 30K; Nasdaq hits record'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:05PM',\n","  'Tesla Plans Key Addition To China Production; 9,500 EVs Recalled'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '04:03PM',\n","  'GM Vs. Ford: 5 Reasons Why One Is Pulling Ahead On Electric Cars'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '03:05PM',\n","  'Q3 Earnings Scorecard and Analyst Reports for Tesla, JPMorgan & Comcast'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '02:57PM',\n","  \"Tesla's upcoming S&P 500 debut fuels 'crazy' trading volume\"],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '02:22PM',\n","  'Tesla Recalls 9,500 Cars One Week After \"Consumer Reports\" Dings Its Reliability'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '02:17PM',\n","  'US STOCKS-S&P 500, Dow retreat from record highs after bleak jobless data'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '02:08PM',\n","  'Tesla Recalls Over 9K Model Xs, 400 Model Ys'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '01:44PM',\n","  'The #1 Insider Signal Every Trader Should Know'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '01:39PM',\n","  'Dow Jones Falls As Jobless Claims Rise; Slack Stock Explodes On This News'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '01:15PM',\n","  \"How High Can Tesla Go? Let's Look at the Chart\"],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '01:04PM',\n","  'Now Worth Over Half a Trillion Dollars, Teslas Stock Rose Over 500% This Year'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '12:14PM',\n","  'Dow Jones Slips Below 30,000 As Jobless Claims Weigh; Apple Rises But These EV Stocks Skid'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '12:04PM',\n","  'Tesla to Recall 9,537 Vehicles Including Model X and Model Y'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '12:00PM',\n","  'Dow Jones Falls From Record Highs; Tesla Reverses Amid Recall, While Chinese EV Stocks Li Auto, Nio, Xpeng Tumble'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '11:40AM',\n","  'PCAR or TSLA: Which Is the Better Value Stock Right Now?'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '11:02AM',\n","  'Nikola, Tesla Shares Fall as EV Rally Frenzy Comes to a Halt'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '10:43AM',\n","  'Tesla recall affects more than 9,000 Model X, Model Y'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '10:41AM',\n","  'US STOCKS-S&P 500, Dow dip as labor market recovery slows'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '09:48AM',\n","  'Tesla plans to produce electric car chargers in China, document shows'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '09:42AM',\n","  'Tesla plans to produce electric car chargers in China, document shows'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '09:22AM',\n","  \"Tesla's Musk Says Company Might Launch Hatchback in Europe\"],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '08:33AM',\n","  \"Nikola's stock tumbles to put record 8-day win streak in danger\"],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '08:18AM',\n","  'Dow Jones Futures: Dow Makes History, As Tesla, Nio Set Record Highs; Hot IPO Stocks Corsair, Palantir Skyrocket'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '06:45AM',\n","  'Tesla issues two recalls covering 9,500 U.S. vehicles: NHTSA'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '05:30AM',\n","  'Improving Cash Flows Put GM and Ford Dividends in Line for Restoration'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '03:21AM',\n","  'Tesla Faces Class Action Over Allegedly Covering Up Model S, X Suspension Defects'],\n"," ['TSLA',\n","  'Nov-25-20',\n","  '12:25AM',\n","  \"Here's What's Pushing Tesla Stock Toward $600 -- and Beyond\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:49PM',\n","  \"Tesla Giga Berlin To Feature 'Largest Battery Cell Plant In The World,' Musk Says\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '07:01PM',\n","  'Jim Cramer: The 10 Tipping Points That Took Us to Dow 30,000'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '07:00PM',\n","  'The Investment Trend That Could Send Tesla To $2 Trillion'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '06:51PM',\n","  'Is GM Stock A Buy? General Motors Hits EV Accelerator, Races Toward Record Highs'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '05:45PM',\n","  \"Elon Musk becomes world's second richest person\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:43PM',\n","  'Is Tesla About to Get Crushed by General Motors?'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:42PM',\n","  'US STOCKS-Dow scales 30,000 on vaccine headway, Biden transition'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:24PM',\n","  'Dow Jones Surges Above 30,000, Led By JPMorgan, American Express; FedEx Hits Buy Point'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:03PM',\n","  'Tesla, Nikola Rally While Chinese Electric Car Stocks Veer Off'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:00PM',\n","  'US STOCKS-Dow scales 30,000 on vaccine headway, Biden transition'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '03:11PM',\n","  'Dow Breaks Key Barrier As Trump Agrees To Power Transfer; Tesla Among Top Performers'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '02:58PM',\n","  'US STOCKS-Dow tops 30,000 on vaccine progress, Biden transition'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '02:40PM',\n","  'New Battery Cells Could Give Tesla Semi More Than 600 Miles Of Range'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '02:16PM',\n","  'The Dow hitting 30,000 may just be the start, hints investing legend'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '01:54PM',\n","  'Here is the 4th Most Popular Stock Among Hedge Funds'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '01:36PM',\n","  'Tesla Market Cap Surges, Topping $500 Billion for First Time'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '01:33PM',\n","  'Dow Jones Up 450 Points, Hits 30,000 As Tesla Gets Extended'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '01:21PM',\n","  'Top Consumer Discretionary Stocks for December 2020'],\n"," ['TSLA', 'Nov-24-20', '12:44PM', 'Teslas market cap zooms past $500 billion'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '12:24PM',\n","  'How The Biden Administration Could Benefit EV Players In The US'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '12:17PM',\n","  'US STOCKS-Dow hits 30,000 on vaccine progress, Biden transition'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '12:03PM',\n","  'Dow Jones Jumps 500 Points, As Trump Agrees To Biden Transition; Nio, Tesla Race To Record Highs'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '11:46AM',\n","  'Tesla Passes $500B Market Cap As S&P Inclusion Approaches'],\n"," ['TSLA', 'Nov-24-20', '11:33AM', 'Why Tesla Stock Jumped Sharply on Tuesday'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '10:59AM',\n","  'Markets Awaits Transition and Economic Data'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '10:44AM',\n","  'US STOCKS-Dow hits all-time high on Biden transition, rebound hopes'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '10:38AM',\n","  'Tesla mulls expanding in Europe with compact vehicles: CEO'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '10:19AM',\n","  'Transition, Vaccines and Retail Sales Make for a Good Week'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:49AM',\n","  'Auto Stock Roundup: TSLA to Enter S&P 500, GM to Rev Up EV Investment & More'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:43AM',\n","  'Dow Jones Today Leads Early Rally As GSA Supports White House Transition; Tesla Stock Leads E-Auto Rally'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:43AM',\n","  'Tesla Hits $500 Billion Mark After Soaring 547% This Year'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:42AM',\n","  \"NIO's Market Cap Just Passed General Motors: Can It Live Up to Its Valuation?\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:34AM',\n","  \"Tesla's Elon Musk Is Now the World's Second-Richest Person\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '09:13AM',\n","  'US STOCKS-Wall St poised to jump on Biden transition, rebound hopes'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '08:51AM',\n","  'Tesla (TSLA) to Procure Batteries From LG Chem for Model Y'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '08:28AM',\n","  'Dow Jones Futures: Latest Bitcoin Play In Buy Zone As Tesla, Nio, Xpeng Fly; Apple Stock Breaks Support'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '07:52AM',\n","  'Elon Musk, Janet Yellen, General Motors, Best Buy - 5 Things You Must Know Tuesday'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '07:41AM',\n","  'Tesla set to breach $500 billion in market value'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '07:41AM',\n","  'Tesla market value crosses $500 billion as shares surge six-fold this year'],\n"," ['TSLA', 'Nov-24-20', '07:30AM', 'Why Do Baby Boomers Hate Tesla?'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '06:27AM',\n","  'Teslas stock powered up to a record as Wedbush analyst raised bull-case target to $1,000'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:59AM',\n","  \"Elon Musk Surpasses Bill Gates To Become World's Second Richest\"],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '04:31AM',\n","  'Tesla FSD Beta 5 Coming In Few Days With Significant Improvement, Musk Says'],\n"," ['TSLA',\n","  'Nov-24-20',\n","  '03:07AM',\n","  'Tesla Rolls Out Firmware Update After Hacker Discovers Model X Security Flaw'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '09:55PM',\n","  'Elon Musk is now worlds second-richest person, as net worth has grown more than $100 billion this year'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '05:54PM',\n","  'Security Robots of the Future and Investing in MaaS: Join Knightscope CEO William Li for Fireside Chat on Dec. 9'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '05:48PM',\n","  'Tesla Stock to $1,000? The Bull Case for Another Double'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '05:34PM',\n","  'Think the Model S Is Fast? Tesla Raced to $500 Billion in Value in Less Than a Year.'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '05:26PM',\n","  'Tesla Stock Could Surge 104% to $1,000, According to This Analyst'],\n"," ['TSLA', 'Nov-23-20', '05:24PM', 'U.S. Markets Rise on Vaccine Optimism'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '05:15PM',\n","  'Tesla, Align Technology Help Nasdaq Investors Smile'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '04:47PM',\n","  'US STOCKS-Cyclical gains lift stocks, Yellen news gives brief boost'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '04:01PM',\n","  'US STOCKS-Cyclical boost lifts stocks; Yellen news gives short bump'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '03:01PM',\n","  'Dow Jones Adds To Gains, Nasdaq Turns Positive; Tesla Stock At New High'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '02:56PM',\n","  'US STOCKS-Stocks rise on cyclical boost but megacaps curb gains'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '02:13PM',\n","  'Blink Chargings stock nearly triples in 6 days amid a great deal of market interest in the EV sector'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '02:04PM',\n","  'Tesla (TSLA) Will Be Part of the S&P 500 Come December'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '01:05PM',\n","  'Tesla defies doubters as builds on rally ahead of S&P 500 debut'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:49PM',\n","  'Short-sellers disappear as market gains to start shortened holiday week'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:33PM',\n","  'US STOCKS-Energy, industrials prop up Dow; tech mega-caps slide'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:25PM',\n","  \"Is Tesla Stock A Buy Right Now? Here's What Earnings, Charts Show\"],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:15PM',\n","  'Dow Jones Leads As Stock Market Trims Gains; Apple Falls But Tesla, Nio Surge'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:01PM',\n","  'Dow Jones Jumps 300 Points On Vaccine News, But Apple Slides; Tesla Surges To Record High, While Nio Races Higher'],\n"," ['TSLA',\n","  'Nov-23-20',\n","  '12:00PM',\n","  \"The EPA says the Ford Mustang Mach-E's electric range is a lackluster 211-300 miles\"],\n"," ['TSLA', 'Nov-23-20', '11:36AM', 'Why Tesla Stock Jumped 7% Early Today'],\n"," ['GOOG',\n","  'Nov-26-20',\n","  '09:10AM',\n","  'GDPR enforcement must level up to catch big tech, report warns'],\n"," ['GOOG',\n","  'Nov-26-20',\n","  '07:00AM',\n","  '10 Stocks to Be Thankful for This Thanksgiving'],\n"," ['GOOG',\n","  'Nov-26-20',\n","  '06:45AM',\n","  'If You Have $1,000 and 10 Years to Wait, Buy These 2 Stocks Now'],\n"," ['GOOG',\n","  'Nov-26-20',\n","  '06:00AM',\n","  'The S&P 500 Could Jump 20% Next Year. Three Strategists Explain Why.'],\n"," ['GOOG', 'Nov-26-20', '05:51AM', '5 Perfect Stocks to Gobble Up Right Now'],\n"," ['GOOG',\n","  'Nov-26-20',\n","  '01:00AM',\n","  'Forget the Bargain Basement. Bet on the Next Big Thing'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '05:00PM',\n","  'Big Oil And Big Tech Are Spending Billions On Renewable Energy'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '02:50PM',\n","  'Amazon Cloud Outage Hits Customers Including Roku, Adobe'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '02:30PM',\n","  'Why Maradona Was Better Than Messi and Ronaldo'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '01:19PM',\n","  'Salesforce acquisition of Slack could trigger M&A wave, analyst says'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '01:11PM',\n","  \"What will tomorrow's tech look like? Ask someone who can't see\"],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '12:26PM',\n","  'Amazon Web Services suffers amid widespread issues with online applications'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '12:00PM',\n","  'Self-Driving-Car Firm Waymo Sharpens Covid Worker-Safety Rules'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '09:49AM',\n","  'Lookback: Tao Values 2019 Alphabet Inc (GOOG) Thesis'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '09:21AM',\n","  'HP CEO: COVID-19 pandemic has reinforced our consumer business'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '09:13AM',\n","  'Why Upcoming IPO Roblox Could Become the YouTube of Gaming'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '08:39AM',\n","  'Colin Kaepernick will not play in the NFL again: Emmanuel Acho'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '08:15AM',\n","  'France defies U.S. and starts levying digital tax on tech giants. But will this change with a Biden presidency?'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '07:30AM',\n","  'Hedge Funds Are Finally Beating the Market in 2020. Here Are Their Top Holdings.'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '06:33AM',\n","  'Amazon (AMZN) Cloud Clientele Improves as Zalando Picks AWS'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '06:30AM',\n","  'Equal-Weighted Indexes Are Winningand Thats a Good Sign for Stocks'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '02:50AM',\n","  'Google Thinking Of 2023 With Its Gaming Service Stadia As War With Fellow Tech Giants Heats Up'],\n"," ['GOOG',\n","  'Nov-25-20',\n","  '01:30AM',\n","  'South Korea Unveils AI Chip to Maintain Semiconductor Leadership'],\n"," ['GOOG', 'Nov-24-20', '06:09PM', 'Airbnb Prepares to IPO'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '04:58PM',\n","  'YouTube bans One America News Network from posting new videos for a week'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '03:35PM',\n","  'YouTube Suspends OAN, a Trump Favorite, For Touting Covid Cure'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '01:14PM',\n","  'Senators Ask YouTube to Remove Election Misinformation'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '12:59PM',\n","  'Google Reportedly Wants to Buy Indian Social Media Firm ShareChat'],\n"," ['GOOG', 'Nov-24-20', '11:39AM', 'Google Back In Buy Zone'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '09:52AM',\n","  'Lookback: Wedgewood Partners 2019 Alphabet Inc (GOOGL) Thesis'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '08:32AM',\n","  'Apple (AAPL) Seeks Tough Data Protection in Google Lawsuit'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '06:00AM',\n","  'Hyperbolic to compare unpaid college sports to slavery: Emmanuel Acho'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '05:24AM',\n","  'Tech giants ask Malaysia PM to reinstate foreign ship cable waiver: report'],\n"," ['GOOG',\n","  'Nov-24-20',\n","  '04:12AM',\n","  \"Uber For Trucks  Manbang  Piles On Another $1.7B Funding Over Google, SoftBank's, Ahead Of Highly-Anticipated IPO\"],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '10:39PM',\n","  'SoftBank-Led Round Values Uber-Like Truck Startup at $12 Billion'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '04:01PM',\n","  'U.S. states prepare second antitrust lawsuit against Google for December'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '03:55PM',\n","  'U.S. states prepping second antitrust lawsuit against Google for next month'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '02:40PM',\n","  'Morgan\\xa0Stanleys\\xa0Lynch Wins Big on Growth Bets'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '12:27PM',\n","  'Googles new advertising technology is under the regulatory microscope after a group of businesses called for it to be legally blocked'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '12:27PM',\n","  'Google Cloud is creating a new type of digital banking platform with this lender'],\n"," ['GOOG', 'Nov-23-20', '12:07PM', 'Why Roku Stock Jumped on Monday'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '11:04AM',\n","  'Dow Rallies as Investors Cheer Possible Return of Yellen, Vaccine News'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '10:36AM',\n","  'Russia opens case against Google, saying it failed to delete banned content'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '10:17AM',\n","  'Dow Rallies on News Biden to Pick Yellen as Treasury Secretary'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '10:13AM',\n","  \"Google brings 'The Mandalorian' to AR in its new app\"],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '09:00AM',\n","  'Snap to Pay $1 Million a Day to Creators for Spotlight Videos'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '08:46AM',\n","  \"Digital marketing firms file UK competition complaint against Google's Privacy Sandbox\"],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '08:19AM',\n","  'Google Ad Changes Targeted by Rivals in U.K. Complaint'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '07:00AM',\n","  'Foxconn Plant Championed by Trump Lands Google Server Contract'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '06:00AM',\n","  'Influencers with Andy Serwer: Emmanuel Acho'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '06:00AM',\n","  'Emmanuel Acho: Donald Trump cant dictate the perception of the NFL'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '03:59AM',\n","  'Google under review for possible British competition enquiry'],\n"," ['GOOG',\n","  'Nov-23-20',\n","  '03:44AM',\n","  \"UK's competition regulator looking at formal investigation into Google\"],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '12:27PM',\n","  'These Stocks Would Have Doubled Your Money Last Year'],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '12:00PM',\n","  'Matthew McConaughey: Social media has been good for business'],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '09:54AM',\n","  'Up Over 250% in 2020, Is Pinterest Stock Still a Buy?'],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '08:00AM',\n","  'Kominerss Conundrums: Country Music Can Save the World'],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '06:56AM',\n","  'This Digital Health Startup Has Joined Forces With Amazon and Nike. Should Investors Take Notice?'],\n"," ['GOOG',\n","  'Nov-22-20',\n","  '06:00AM',\n","  \"Matthew McConaughey explains why hes inspired by Marc Benioff's 'new capitalism'\"],\n"," ['GOOG',\n","  'Nov-21-20',\n","  '05:23PM',\n","  'Western Union Grabs 15% Stake In Saudi Digital Payments Business'],\n"," ['GOOG',\n","  'Nov-21-20',\n","  '09:00AM',\n","  'The Cloud, AI and the Transformation of Retail'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '06:05PM',\n","  'Apple to AT&T Wary of Full Disclosure in Google Antitrust Case'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '04:29PM',\n","  'Apple, GroupM, others ask for tough protection for data in Google lawsuit'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '04:28PM',\n","  'Apple, AT&T ask for tough protection for data in Google lawsuit'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '04:22PM',\n","  \"Blind man, 'born to run,' completes solo 5K with trial app to guide him\"],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '04:11PM',\n","  \"CORRECTED-Blind man, 'born to run,' completes solo 5K with trial app to guide him\"],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '02:16PM',\n","  'Alphabet Could Rally $100 According to the Charts'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '02:00PM',\n","  '3 Stocks Continuing to Shine in the Overvalued Internet Services Industry'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '01:36PM',\n","  'Twitter Stock Has Been an Eyesore, But Fleets Could Change That'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '12:53PM',\n","  \"Facebook and Twitter enrage users as 'a fantastic way' to sell ads: NYU professor Scott Galloway\"],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '12:01PM',\n","  'Google, Facebook and Twitter threaten to leave Pakistan over censorship law'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '11:34AM',\n","  'Google to Pay Some French Publishers for Content'],\n"," ['GOOG', 'Nov-20-20', '11:00AM', \"Here's My Tech Rundown, Brazilian-Style\"],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '10:24AM',\n","  'The Stocks the Pros Own Usually Beat the Market. Heres a List of Their 10 Most Popular Bets.'],\n"," ['GOOG', 'Nov-20-20', '09:58AM', '30 Richest Cities in the United States'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '09:39AM',\n","  \"'Live anywhere': How Airbnb is surviving COVID-19\"],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '08:56AM',\n","  'The Zacks Analyst Blog Highlights: Google, Microsoft, Texas Instruments, NVIDIA and Skyworks Solutions'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '07:00AM',\n","  'This Top-Performing Mutual Fund Shuns Apple, Facebook, Netflix'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '06:41AM',\n","  'Analyst Sees Snap Hitting $200B Valuation By 2025'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '05:47AM',\n","  'GRAPHIC-French, Italian economies hurt most under second lockdowns'],\n"," ['GOOG',\n","  'Nov-20-20',\n","  '01:21AM',\n","  'Roblox Files For NYSE IPO As Userbase Grows 82% In 2020'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '06:51PM',\n","  'Robotaxi companies get the green light to charge for rides in California'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '04:58PM',\n","  'Robotaxi companies can now win approval to operate in California'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '04:46PM',\n","  'Twitters Jack Dorsey should be fired for being CEO of 2 firms: Big Tech critic Scott Galloway'],\n"," ['GOOG', 'Nov-19-20', '04:21PM', 'Thank you, Chrome team'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '04:01PM',\n","  'Black Friday 2020: Tips for buying the best tech gifts'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '01:35PM',\n","  'New contact tracing apps stir hope for virus fighters in U.S. states'],\n"," ['GOOG', 'Nov-19-20', '01:18PM', 'Tech in the Biden era'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '01:12PM',\n","  'Google Stadia Will Be Available for iOS Soon'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '01:02PM',\n","  'Revamped Google Pay targets PayPal, Venmo, and Apple Pay'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '12:16PM',\n","  \"Sonos CEO on skyrocketing stock price: 'We have an inflection point'\"],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '11:56AM',\n","  \"Google Pay product manager on 'Plex Account' launch\"],\n"," ['GOOG', 'Nov-19-20', '11:44AM', 'Tech Support: What to buy on Black Friday'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '10:49AM',\n","  'Google plans to test end-to-end encryption in Android messages'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '10:47AM',\n","  'Dow Cuts Losses on Tech Strength, Stimulus Hopes'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '10:42AM',\n","  'Sonoss Blowout Quarter and Ambitious Outlook Has Wall Street Gushing. The Stock Is Surging.'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '10:09AM',\n","  'Google signs copyright agreements with six French newspapers'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '09:47AM',\n","  'Google signs copyright agreement with six French newspapers'],\n"," ['GOOG', 'Nov-19-20', '09:45AM', 'Better Buy: Baidu vs. Alphabet'],\n"," ['GOOG',\n","  'Nov-19-20',\n","  '07:41AM',\n","  '5 Tech Giants to Buy at Deep Discount Amid Recent Turmoil']]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"Vml2o6IreI5F"},"source":["## Sentiment Analysis using Vader sentiment analyzer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"3JwfZOjOaMMV","executionInfo":{"status":"ok","timestamp":1606429960487,"user_tz":300,"elapsed":403072,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"3da5935d-68b5-4e75-9ab2-6143002c45a2"},"source":["# NLTK VADER for sentiment analysis\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import nltk\n","nltk.download('vader_lexicon')\n","\n","# Instantiate the sentiment intensity analyzer\n","vader = SentimentIntensityAnalyzer()\n","\n","# Set column names\n","columns = ['ticker', 'date', 'time', 'headline']\n","\n","# Convert the parsed_news list into a DataFrame called 'parsed_and_scored_news'\n","parsed_and_scored_news = pd.DataFrame(parsed_news, columns=columns)\n","\n","# Iterate through the headlines and get the polarity scores using vader\n","scores = parsed_and_scored_news['headline'].apply(vader.polarity_scores).tolist()\n","print(scores)\n","print(type(scores))\n","print(len(scores))\n","\n","# Convert the 'scores' list of dicts into a DataFrame\n","scores_df = pd.DataFrame(scores)\n","\n","# Join the DataFrames of the news and the list of dicts\n","parsed_and_scored_news = parsed_and_scored_news.join(scores_df, rsuffix='_right')\n","\n","# Convert the date column from string to datetime\n","parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\n","\n","parsed_and_scored_news.head()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[{'neg': 0.0, 'neu': 0.531, 'pos': 0.469, 'compound': 0.6486}, {'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.529, 'pos': 0.471, 'compound': 0.7906}, {'neg': 0.0, 'neu': 0.529, 'pos': 0.471, 'compound': 0.7906}, {'neg': 0.183, 'neu': 0.667, 'pos': 0.15, 'compound': -0.1027}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.612, 'pos': 0.388, 'compound': 0.6908}, {'neg': 0.0, 'neu': 0.575, 'pos': 0.425, 'compound': 0.5719}, {'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.5719}, {'neg': 0.0, 'neu': 0.719, 'pos': 0.281, 'compound': 0.4404}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'compound': 0.5719}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.162, 'neu': 0.684, 'pos': 0.154, 'compound': -0.0258}, {'neg': 0.217, 'neu': 0.783, 'pos': 0.0, 'compound': -0.3612}, {'neg': 0.123, 'neu': 0.738, 'pos': 0.139, 'compound': 0.0516}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.123, 'neu': 0.738, 'pos': 0.139, 'compound': 0.0516}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'compound': 0.8807}, {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'compound': 0.1779}, {'neg': 0.099, 'neu': 0.901, 'pos': 0.0, 'compound': -0.0258}, {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'compound': 0.1779}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.719, 'pos': 0.281, 'compound': 0.481}, {'neg': 0.308, 'neu': 0.692, 'pos': 0.0, 'compound': -0.4588}, {'neg': 0.063, 'neu': 0.699, 'pos': 0.239, 'compound': 0.6157}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'compound': 0.1779}, {'neg': 0.242, 'neu': 0.625, 'pos': 0.133, 'compound': -0.34}, {'neg': 0.0, 'neu': 0.825, 'pos': 0.175, 'compound': 0.1779}, {'neg': 0.204, 'neu': 0.796, 'pos': 0.0, 'compound': -0.3182}, {'neg': 0.179, 'neu': 0.66, 'pos': 0.16, 'compound': -0.0516}, {'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.6808}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.395, 'pos': 0.605, 'compound': 0.5574}, {'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compound': -0.296}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.62, 'pos': 0.38, 'compound': 0.5994}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.169, 'neu': 0.831, 'pos': 0.0, 'compound': -0.2584}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.179, 'neu': 0.714, 'pos': 0.107, 'compound': -0.296}, {'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'compound': 0.3818}, {'neg': 0.248, 'neu': 0.752, 'pos': 0.0, 'compound': -0.3182}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.047, 'neu': 0.772, 'pos': 0.181, 'compound': 0.6124}, {'neg': 0.0, 'neu': 0.65, 'pos': 0.35, 'compound': 0.7184}, {'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'compound': 0.5423}, {'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}, {'neg': 0.161, 'neu': 0.638, 'pos': 0.201, 'compound': 0.0951}, {'neg': 0.23, 'neu': 0.619, 'pos': 0.15, 'compound': -0.2263}, {'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.841, 'pos': 0.159, 'compound': 0.1779}, {'neg': 0.291, 'neu': 0.606, 'pos': 0.103, 'compound': -0.4767}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.291, 'neu': 0.606, 'pos': 0.103, 'compound': -0.4767}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.183, 'neu': 0.61, 'pos': 0.207, 'compound': 0.0516}, {'neg': 0.106, 'neu': 0.493, 'pos': 0.401, 'compound': 0.6369}, {'neg': 0.0, 'neu': 0.816, 'pos': 0.184, 'compound': 0.4019}, {'neg': 0.0, 'neu': 0.855, 'pos': 0.145, 'compound': 0.1779}, {'neg': 0.171, 'neu': 0.62, 'pos': 0.209, 'compound': 0.128}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'compound': 0.4404}, {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}, {'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'compound': 0.6369}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.296, 'neu': 0.435, 'pos': 0.27, 'compound': -0.0772}, {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.569, 'pos': 0.431, 'compound': 0.6486}, {'neg': 0.087, 'neu': 0.63, 'pos': 0.283, 'compound': 0.5423}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.159, 'neu': 0.69, 'pos': 0.152, 'compound': -0.0258}, {'neg': 0.161, 'neu': 0.511, 'pos': 0.328, 'compound': 0.3182}, {'neg': 0.121, 'neu': 0.561, 'pos': 0.318, 'compound': 0.6369}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound': 0.25}, {'neg': 0.156, 'neu': 0.556, 'pos': 0.289, 'compound': 0.296}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.86, 'pos': 0.14, 'compound': 0.3818}, {'neg': 0.205, 'neu': 0.536, 'pos': 0.259, 'compound': 0.1531}, {'neg': 0.0, 'neu': 0.825, 'pos': 0.175, 'compound': 0.1779}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.173, 'neu': 0.617, 'pos': 0.21, 'compound': 0.0772}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.566, 'pos': 0.434, 'compound': 0.7096}, {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'compound': 0.4019}, {'neg': 0.0, 'neu': 0.607, 'pos': 0.393, 'compound': 0.7027}, {'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'compound': -0.3818}, {'neg': 0.0, 'neu': 0.687, 'pos': 0.313, 'compound': 0.4927}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4215}, {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'compound': 0.4404}, {'neg': 0.162, 'neu': 0.684, 'pos': 0.154, 'compound': -0.0258}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.209, 'neu': 0.62, 'pos': 0.171, 'compound': -0.128}, {'neg': 0.222, 'neu': 0.778, 'pos': 0.0, 'compound': -0.5719}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.859, 'pos': 0.141, 'compound': 0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'compound': 0.2263}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.629, 'pos': 0.371, 'compound': 0.6486}, {'neg': 0.17, 'neu': 0.667, 'pos': 0.163, 'compound': -0.0258}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.21, 'neu': 0.556, 'pos': 0.235, 'compound': 0.1027}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.797, 'pos': 0.203, 'compound': 0.4215}, {'neg': 0.197, 'neu': 0.803, 'pos': 0.0, 'compound': -0.4019}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.638, 'pos': 0.362, 'compound': 0.5267}, {'neg': 0.259, 'neu': 0.741, 'pos': 0.0, 'compound': -0.4215}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.093, 'neu': 0.683, 'pos': 0.224, 'compound': 0.2732}, {'neg': 0.0, 'neu': 0.534, 'pos': 0.466, 'compound': 0.7269}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.744, 'pos': 0.256, 'compound': 0.4754}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.4588}, {'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.4215}, {'neg': 0.0, 'neu': 0.899, 'pos': 0.101, 'compound': 0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'compound': 0.0772}, {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4215}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.865, 'pos': 0.135, 'compound': 0.3612}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.652, 'pos': 0.348, 'compound': 0.5859}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.758, 'pos': 0.242, 'compound': 0.6249}, {'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.6369}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.34}, {'neg': 0.0, 'neu': 0.685, 'pos': 0.315, 'compound': 0.5574}, {'neg': 0.425, 'neu': 0.575, 'pos': 0.0, 'compound': -0.5719}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.726, 'pos': 0.274, 'compound': 0.5267}, {'neg': 0.0, 'neu': 0.676, 'pos': 0.324, 'compound': 0.5859}, {'neg': 0.0, 'neu': 0.806, 'pos': 0.194, 'compound': 0.34}, {'neg': 0.0, 'neu': 0.899, 'pos': 0.101, 'compound': 0.2263}, {'neg': 0.0, 'neu': 0.787, 'pos': 0.213, 'compound': 0.5574}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.862, 'pos': 0.138, 'compound': 0.34}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.5423}, {'neg': 0.0, 'neu': 0.49, 'pos': 0.51, 'compound': 0.6369}, {'neg': 0.0, 'neu': 0.611, 'pos': 0.389, 'compound': 0.6249}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.4019}, {'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'compound': 0.7184}, {'neg': 0.0, 'neu': 0.618, 'pos': 0.382, 'compound': 0.6059}, {'neg': 0.0, 'neu': 0.679, 'pos': 0.321, 'compound': 0.7964}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.173, 'neu': 0.827, 'pos': 0.0, 'compound': -0.3182}, {'neg': 0.136, 'neu': 0.5, 'pos': 0.364, 'compound': 0.4939}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'compound': 0.34}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.123, 'neu': 0.877, 'pos': 0.0, 'compound': -0.1027}, {'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.5719}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'compound': 0.5719}, {'neg': 0.162, 'neu': 0.684, 'pos': 0.154, 'compound': -0.0258}, {'neg': 0.0, 'neu': 0.826, 'pos': 0.174, 'compound': 0.2732}, {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.707, 'pos': 0.293, 'compound': 0.4404}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound': 0.3612}, {'neg': 0.242, 'neu': 0.625, 'pos': 0.133, 'compound': -0.34}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.722, 'pos': 0.278, 'compound': 0.4019}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.169, 'neu': 0.831, 'pos': 0.0, 'compound': -0.2584}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.179, 'neu': 0.714, 'pos': 0.107, 'compound': -0.296}, {'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'compound': 0.5423}, {'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}, {'neg': 0.196, 'neu': 0.804, 'pos': 0.0, 'compound': -0.5994}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.145, 'neu': 0.598, 'pos': 0.256, 'compound': 0.3182}, {'neg': 0.277, 'neu': 0.723, 'pos': 0.0, 'compound': -0.3182}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.327, 'neu': 0.673, 'pos': 0.0, 'compound': -0.34}, {'neg': 0.348, 'neu': 0.652, 'pos': 0.0, 'compound': -0.7003}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'compound': 0.4019}, {'neg': 0.174, 'neu': 0.826, 'pos': 0.0, 'compound': -0.2263}, {'neg': 0.16, 'neu': 0.84, 'pos': 0.0, 'compound': -0.2263}, {'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.743}, {'neg': 0.098, 'neu': 0.837, 'pos': 0.065, 'compound': -0.1779}, {'neg': 0.0, 'neu': 0.845, 'pos': 0.155, 'compound': 0.296}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.752, 'pos': 0.248, 'compound': 0.5106}, {'neg': 0.387, 'neu': 0.613, 'pos': 0.0, 'compound': -0.743}, {'neg': 0.0, 'neu': 0.847, 'pos': 0.153, 'compound': 0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.123, 'neu': 0.877, 'pos': 0.0, 'compound': -0.1027}, {'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compound': -0.296}, {'neg': 0.216, 'neu': 0.784, 'pos': 0.0, 'compound': -0.296}, {'neg': 0.0, 'neu': 0.784, 'pos': 0.216, 'compound': 0.296}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.686, 'pos': 0.314, 'compound': 0.4939}, {'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'compound': 0.1779}, {'neg': 0.0, 'neu': 0.758, 'pos': 0.242, 'compound': 0.4939}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.254, 'neu': 0.746, 'pos': 0.0, 'compound': -0.34}, {'neg': 0.274, 'neu': 0.726, 'pos': 0.0, 'compound': -0.34}, {'neg': 0.172, 'neu': 0.828, 'pos': 0.0, 'compound': -0.4019}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.17, 'neu': 0.66, 'pos': 0.17, 'compound': 0.0}, {'neg': 0.297, 'neu': 0.703, 'pos': 0.0, 'compound': -0.4215}, {'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'compound': -0.1027}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'compound': 0.4754}, {'neg': 0.0, 'neu': 0.446, 'pos': 0.554, 'compound': 0.7351}, {'neg': 0.0, 'neu': 0.732, 'pos': 0.268, 'compound': 0.296}, {'neg': 0.0, 'neu': 0.876, 'pos': 0.124, 'compound': 0.1779}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.327, 'neu': 0.673, 'pos': 0.0, 'compound': -0.5267}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 0.537, 'pos': 0.463, 'compound': 0.7845}, {'neg': 0.289, 'neu': 0.711, 'pos': 0.0, 'compound': -0.6908}, {'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.3612}, {'neg': 0.0, 'neu': 0.682, 'pos': 0.318, 'compound': 0.6369}, {'neg': 0.085, 'neu': 0.709, 'pos': 0.206, 'compound': 0.4019}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.2023}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'compound': -0.1027}, {'neg': 0.0, 'neu': 0.722, 'pos': 0.278, 'compound': 0.4019}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.329, 'neu': 0.268, 'pos': 0.403, 'compound': 0.2732}, {'neg': 0.0, 'neu': 0.807, 'pos': 0.193, 'compound': 0.4767}, {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.2732}, {'neg': 0.0, 'neu': 0.686, 'pos': 0.314, 'compound': 0.4939}, {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}, {'neg': 0.217, 'neu': 0.783, 'pos': 0.0, 'compound': -0.3612}]\n","<class 'list'>\n","300\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ticker</th>\n","      <th>date</th>\n","      <th>time</th>\n","      <th>headline</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AMZN</td>\n","      <td>2020-11-26</td>\n","      <td>04:52PM</td>\n","      <td>Amazon spends $500m on bonuses for Christmas s...</td>\n","      <td>0.000</td>\n","      <td>0.531</td>\n","      <td>0.469</td>\n","      <td>0.6486</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AMZN</td>\n","      <td>2020-11-26</td>\n","      <td>03:27PM</td>\n","      <td>The Amazon of Africa is trying to enable third...</td>\n","      <td>0.000</td>\n","      <td>0.892</td>\n","      <td>0.108</td>\n","      <td>0.1779</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AMZN</td>\n","      <td>2020-11-26</td>\n","      <td>01:12PM</td>\n","      <td>Amazon to give $500 million in holiday bonuses...</td>\n","      <td>0.000</td>\n","      <td>0.529</td>\n","      <td>0.471</td>\n","      <td>0.7906</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AMZN</td>\n","      <td>2020-11-26</td>\n","      <td>01:05PM</td>\n","      <td>Amazon to give $500 million in holiday bonuses...</td>\n","      <td>0.000</td>\n","      <td>0.529</td>\n","      <td>0.471</td>\n","      <td>0.7906</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AMZN</td>\n","      <td>2020-11-26</td>\n","      <td>11:00AM</td>\n","      <td>Here's the Critically Important Point Investor...</td>\n","      <td>0.183</td>\n","      <td>0.667</td>\n","      <td>0.150</td>\n","      <td>-0.1027</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ticker        date     time  ...    neu    pos  compound\n","0   AMZN  2020-11-26  04:52PM  ...  0.531  0.469    0.6486\n","1   AMZN  2020-11-26  03:27PM  ...  0.892  0.108    0.1779\n","2   AMZN  2020-11-26  01:12PM  ...  0.529  0.471    0.7906\n","3   AMZN  2020-11-26  01:05PM  ...  0.529  0.471    0.7906\n","4   AMZN  2020-11-26  11:00AM  ...  0.667  0.150   -0.1027\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"tmujZQLTbXAq","executionInfo":{"status":"ok","timestamp":1606429960750,"user_tz":300,"elapsed":403333,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"7d295d3d-1a77-4d29-a39a-9f38818eda35"},"source":["plt.rcParams['figure.figsize'] = [10, 6]\n","\n","# Group by date and ticker columns from scored_news and calculate the mean\n","mean_scores = parsed_and_scored_news.groupby(['ticker','date']).mean()\n","\n","# Unstack the column ticker\n","mean_scores = mean_scores.unstack()\n","\n","# Get the cross-section of compound in the 'columns' axis\n","mean_scores = mean_scores.xs('compound', axis=\"columns\").transpose()\n","\n","# Plot a bar chart with pandas\n","mean_scores.plot(kind = 'bar')\n","plt.grid()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"3xKyCpLLeO_A"},"source":["## Sentiment Analysis using finbert model"]},{"cell_type":"code","metadata":{"id":"VVJBcSLTePfO","executionInfo":{"status":"ok","timestamp":1606429960751,"user_tz":300,"elapsed":403330,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}}},"source":["# Set column names\n","columns = ['ticker', 'date', 'time', 'headline']\n","\n","# Convert the parsed_news list into a DataFrame called 'parsed_news_df'\n","parsed_news_df = pd.DataFrame(parsed_news, columns=columns)\n","\n","# save datafram to json\n","parsed_news_df.to_json(os.path.join(os.path.join(finBERT_repo_path,'data'), 'parsed_news.json'))\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIsFWEXQgXpR","executionInfo":{"status":"ok","timestamp":1606430059947,"user_tz":300,"elapsed":502521,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"f15ffe82-7c6d-4f60-8fe5-08870691f082"},"source":["%%bash\n","source activate finbert\n","conda env list\n","cd /content/finBERT/\n","\n","python \n","# python code starts here\n","from pathlib import Path\n","import sys\n","sys.path.append('..')\n","import argparse\n","import shutil\n","import os\n","import logging\n","from textblob import TextBlob\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n","from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import *\n","\n","from finbert.finbert import *\n","import finbert.utils as tools\n","from pprint import pprint\n","from sklearn.metrics import classification_report\n","\n","import pandas as pd\n","\n","project_dir = Path.cwd()\n","print(project_dir)\n","# finBERT_repo_path = '/content/finBERT'\n","\n","pd.set_option('max_colwidth', -1)\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.ERROR)\n","\n","lm_path = project_dir/'models'/'language_model'/'finbertTRC2'\n","cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n","cl_data_path = project_dir/'data'/'sentiment_data'\n","\n","# load DataFrame of web scraped headlines\n","parsed_and_scored_news = pd.read_json(os.path.join(os.path.join(project_dir,'data'), 'parsed_news.json'))\n","\n","# load finbert model\n","model = BertForSequenceClassification.from_pretrained(cl_path,cache_dir=True, num_labels=3)\n","\n","# iterate through each headlines and get score\n","scores = []\n","for text in parsed_and_scored_news['headline']:\n","  result = predict(text,model)\n","  scores.append(result.sentiment_score.mean())\n","\n","# Convert the 'scores' list into a DataFrame\n","scores_df = pd.DataFrame(scores, columns=['scores'])\n","print(scores_df.head())\n","\n","# Join the DataFrames of the news and the list of dicts\n","parsed_and_scored_news = parsed_and_scored_news.join(scores_df, rsuffix='_right')\n","print(parsed_and_scored_news.head())\n","\n","# Convert the date column from string to datetime\n","parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\n","parsed_and_scored_news.head()\n","\n","# save dataframe to json\n","parsed_and_scored_news.to_json(os.path.join(os.path.join(project_dir,'data'), 'parsed_and_scored_news.json'))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["# conda environments:\n","#\n","base                     /usr/local\n","finbert               *  /usr/local/envs/finbert\n","\n","/content/finBERT\n","     scores\n","0 -0.022022\n","1  0.056744\n","2  0.457826\n","3 -0.306085\n","4 -0.958612\n","    ticker    ...       scores\n","0    AMZN     ...    -0.022022\n","1    AMZN     ...     0.056744\n","10   AMZN     ...    -0.604638\n","100  TSLA     ...    -0.743399\n","101  TSLA     ...    -0.320668\n","\n","[5 rows x 5 columns]\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","11/26/2020 22:32:42 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/finBERT/models/classifier_model/finbert-sentiment from cache at /content/finBERT/models/classifier_model/finbert-sentiment\n","11/26/2020 22:32:42 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","11/26/2020 22:32:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:45 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:45 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   tokens: [CLS] amazon spends $ 500 ##m on bonuses for christmas staff [SEP]\n","11/26/2020 22:32:45 - INFO - finbert.utils -   input_ids: 101 9733 15970 1002 3156 2213 2006 29563 2005 4234 3095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:45 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:45 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   tokens: [CLS] the amazon of africa is trying to enable third - party e - commerce rather than sell more stuff [SEP]\n","11/26/2020 22:32:45 - INFO - finbert.utils -   input_ids: 101 1996 9733 1997 3088 2003 2667 2000 9585 2353 1011 2283 1041 1011 6236 2738 2084 5271 2062 4933 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:45 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:46 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:46 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   tokens: [CLS] the s & p 500 could jump 20 % next year . [SEP]\n","11/26/2020 22:32:46 - INFO - finbert.utils -   input_ids: 101 1996 1055 1004 1052 3156 2071 5376 2322 1003 2279 2095 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:46 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:46 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   tokens: [CLS] dow jones , nas ##da ##q hit highs amid corona ##virus news as tesla , ni ##o , boeing rally ; sales ##force - slack deal near ? [SEP]\n","11/26/2020 22:32:46 - INFO - finbert.utils -   input_ids: 101 23268 3557 1010 17235 2850 4160 2718 26836 13463 21887 23350 2739 2004 26060 1010 9152 2080 1010 10321 8320 1025 4341 14821 1011 19840 3066 2379 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:46 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   tokens: [CLS] tesla ( ts ##la ) recalls more than 9 , 500 suv ##s on safety concerns [SEP]\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_ids: 101 26060 1006 24529 2721 1007 17722 2062 2084 1023 1010 3156 15620 2015 2006 3808 5936 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:47 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   tokens: [CLS] these 3 stocks took off during trump ' s presidency . [SEP]\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_ids: 101 2122 1017 15768 2165 2125 2076 8398 1005 1055 8798 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:47 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   tokens: [CLS] forget the bargain basement . [SEP]\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_ids: 101 5293 1996 17113 8102 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   tokens: [CLS] dow jones slips 173 points after hitting 30 , 000 ; nas ##da ##q leads market [SEP]\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_ids: 101 23268 3557 17433 19410 2685 2044 7294 2382 1010 2199 1025 17235 2850 4160 5260 3006 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   tokens: [CLS] tesla stock rises again , creating another problem for index funds [SEP]\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_ids: 101 26060 4518 9466 2153 1010 4526 2178 3291 2005 5950 5029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   tokens: [CLS] us stocks - s & p 500 , dow pull back from all - time closing highs after grim job ##less data [SEP]\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 1055 1004 1052 3156 1010 23268 4139 2067 2013 2035 1011 2051 5494 26836 2044 11844 3105 3238 2951 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   tokens: [CLS] stock market news live updates : wall street catches breath after dow hits 30 ##k ; nas ##da ##q hits record [SEP]\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_ids: 101 4518 3006 2739 2444 14409 1024 2813 2395 11269 3052 2044 23268 4978 2382 2243 1025 17235 2850 4160 4978 2501 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   tokens: [CLS] tesla plans key addition to china production ; 9 , 500 ev ##s recalled [SEP]\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_ids: 101 26060 3488 3145 2804 2000 2859 2537 1025 1023 1010 3156 23408 2015 7383 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   tokens: [CLS] gm vs . ford : 5 reasons why one is pulling ahead on electric cars [SEP]\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_ids: 101 13938 5443 1012 4811 1024 1019 4436 2339 2028 2003 4815 3805 2006 3751 3765 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   tokens: [CLS] 5 perfect stocks to go ##bble up right now [SEP]\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_ids: 101 1019 3819 15768 2000 2175 11362 2039 2157 2085 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   tokens: [CLS] q ##3 earnings score ##card and analyst reports for tesla , jp ##mo ##rgan & com ##cast [SEP]\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_ids: 101 1053 2509 16565 3556 11522 1998 12941 4311 2005 26060 1010 16545 5302 16998 1004 4012 10526 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   tokens: [CLS] tesla ' s upcoming s & p 500 debut fuels ' crazy ' trading volume [SEP]\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_ids: 101 26060 1005 1055 9046 1055 1004 1052 3156 2834 20145 1005 4689 1005 6202 3872 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   tokens: [CLS] tesla recalls 9 , 500 cars one week after \" consumer reports \" ding ##s its reliability [SEP]\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_ids: 101 26060 17722 1023 1010 3156 3765 2028 2733 2044 1000 7325 4311 1000 22033 2015 2049 15258 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   tokens: [CLS] us stocks - s & p 500 , dow retreat from record highs after bleak job ##less data [SEP]\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 1055 1004 1052 3156 1010 23268 7822 2013 2501 26836 2044 21657 3105 3238 2951 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   tokens: [CLS] tesla recalls over 9 ##k model x ##s , 400 model y ##s [SEP]\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_ids: 101 26060 17722 2058 1023 2243 2944 1060 2015 1010 4278 2944 1061 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   tokens: [CLS] the # 1 insider signal every trader should know [SEP]\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_ids: 101 1996 1001 1015 25297 4742 2296 17667 2323 2113 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:52 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:52 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   tokens: [CLS] dow jones falls as job ##less claims rise ; slack stock explodes on this news [SEP]\n","11/26/2020 22:32:52 - INFO - finbert.utils -   input_ids: 101 23268 3557 4212 2004 3105 3238 4447 4125 1025 19840 4518 27583 2006 2023 2739 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:52 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:52 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   tokens: [CLS] how high can tesla go ? [SEP]\n","11/26/2020 22:32:52 - INFO - finbert.utils -   input_ids: 101 2129 2152 2064 26060 2175 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:52 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   tokens: [CLS] now worth over half a trillion dollars , tesla ##s stock rose over 500 % this year [SEP]\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_ids: 101 2085 4276 2058 2431 1037 23458 6363 1010 26060 2015 4518 3123 2058 3156 1003 2023 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   tokens: [CLS] dow jones slips below 30 , 000 as job ##less claims weigh ; apple rises but these ev stocks ski ##d [SEP]\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_ids: 101 23268 3557 17433 2917 2382 1010 2199 2004 3105 3238 4447 17042 1025 6207 9466 2021 2122 23408 15768 8301 2094 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   tokens: [CLS] amazon ' s cloud service back up after widespread out ##age [SEP]\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_ids: 101 9733 1005 1055 6112 2326 2067 2039 2044 6923 2041 4270 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   tokens: [CLS] tesla to recall 9 , 53 ##7 vehicles including model x and model y [SEP]\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_ids: 101 26060 2000 9131 1023 1010 5187 2581 4683 2164 2944 1060 1998 2944 1061 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   tokens: [CLS] dow jones falls from record highs ; tesla reverse ##s amid recall , while chinese ev stocks li auto , ni ##o , xp ##eng tumble [SEP]\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_ids: 101 23268 3557 4212 2013 2501 26836 1025 26060 7901 2015 13463 9131 1010 2096 2822 23408 15768 5622 8285 1010 9152 2080 1010 26726 13159 28388 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   tokens: [CLS] pc ##ar or ts ##la : which is the better value stock right now ? [SEP]\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_ids: 101 7473 2906 2030 24529 2721 1024 2029 2003 1996 2488 3643 4518 2157 2085 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   tokens: [CLS] nikola , tesla shares fall as ev rally frenzy comes to a halt [SEP]\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_ids: 101 24794 1010 26060 6661 2991 2004 23408 8320 21517 3310 2000 1037 9190 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:55 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:55 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:55 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   tokens: [CLS] tesla recall affects more than 9 , 000 model x , model y [SEP]\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_ids: 101 26060 9131 13531 2062 2084 1023 1010 2199 2944 1060 1010 2944 1061 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:55 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:55 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:55 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   tokens: [CLS] us stocks - s & p 500 , dow dip as labor market recovery slow ##s [SEP]\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 1055 1004 1052 3156 1010 23268 16510 2004 4450 3006 7233 4030 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:55 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:55 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:55 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   tokens: [CLS] tesla plans to produce electric car chargers in china , document shows [SEP]\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_ids: 101 26060 3488 2000 3965 3751 2482 18649 1999 2859 1010 6254 3065 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:55 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   tokens: [CLS] tesla plans to produce electric car chargers in china , document shows [SEP]\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_ids: 101 26060 3488 2000 3965 3751 2482 18649 1999 2859 1010 6254 3065 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   tokens: [CLS] tesla ' s mu ##sk says company might launch hatch ##back in europe [SEP]\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_ids: 101 26060 1005 1055 14163 6711 2758 2194 2453 4888 11300 5963 1999 2885 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   tokens: [CLS] nikola ' s stock tumble ##s to put record 8 - day win streak in danger [SEP]\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_ids: 101 24794 1005 1055 4518 28388 2015 2000 2404 2501 1022 1011 2154 2663 9039 1999 5473 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   tokens: [CLS] forget the bargain basement . [SEP]\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_ids: 101 5293 1996 17113 8102 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:57 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:57 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:57 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   tokens: [CLS] dow jones futures : dow makes history , as tesla , ni ##o set record highs ; hot ip ##o stocks co ##rsa ##ir , pal ##ant ##ir sky ##rock ##et [SEP]\n","11/26/2020 22:32:57 - INFO - finbert.utils -   input_ids: 101 23268 3557 17795 1024 23268 3084 2381 1010 2004 26060 1010 9152 2080 2275 2501 26836 1025 2980 12997 2080 15768 2522 22381 4313 1010 14412 4630 4313 3712 16901 3388 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:57 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:57 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:57 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   tokens: [CLS] tesla issues two recalls covering 9 , 500 u . s . vehicles : nh ##tsa [SEP]\n","11/26/2020 22:32:57 - INFO - finbert.utils -   input_ids: 101 26060 3314 2048 17722 5266 1023 1010 3156 1057 1012 1055 1012 4683 1024 18699 27110 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:57 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   tokens: [CLS] improving cash flows put gm and ford divide ##nds in line for restoration [SEP]\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_ids: 101 9229 5356 6223 2404 13938 1998 4811 11443 18376 1999 2240 2005 6418 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   tokens: [CLS] tesla faces class action over allegedly covering up model s , x suspension defects [SEP]\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_ids: 101 26060 5344 2465 2895 2058 9382 5266 2039 2944 1055 1010 1060 8636 18419 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   tokens: [CLS] here ' s what ' s pushing tesla stock toward $ 600 - - and beyond [SEP]\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_ids: 101 2182 1005 1055 2054 1005 1055 6183 26060 4518 2646 1002 5174 1011 1011 1998 3458 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   tokens: [CLS] tesla gig ##a berlin to feature ' largest battery cell plant in the world , ' mu ##sk says [SEP]\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_ids: 101 26060 15453 2050 4068 2000 3444 1005 2922 6046 3526 3269 1999 1996 2088 1010 1005 14163 6711 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   tokens: [CLS] jim cramer : the 10 tipping points that took us to dow 30 , 000 [SEP]\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_ids: 101 3958 29433 1024 1996 2184 25486 2685 2008 2165 2149 2000 23268 2382 1010 2199 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   tokens: [CLS] the investment trend that could send tesla to $ 2 trillion [SEP]\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_ids: 101 1996 5211 9874 2008 2071 4604 26060 2000 1002 1016 23458 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:32:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:32:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:32:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   tokens: [CLS] is gm stock a buy ? [SEP]\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_ids: 101 2003 13938 4518 1037 4965 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:32:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:00 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:00 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   tokens: [CLS] el ##on mu ##sk becomes world ' s second richest person [SEP]\n","11/26/2020 22:33:00 - INFO - finbert.utils -   input_ids: 101 3449 2239 14163 6711 4150 2088 1005 1055 2117 18429 2711 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:00 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:00 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   tokens: [CLS] these 2 ip ##o stocks are crushing the stock market on wednesday [SEP]\n","11/26/2020 22:33:00 - INFO - finbert.utils -   input_ids: 101 2122 1016 12997 2080 15768 2024 14527 1996 4518 3006 2006 9317 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:00 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   tokens: [CLS] is tesla about to get crushed by general motors ? [SEP]\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_ids: 101 2003 26060 2055 2000 2131 10560 2011 2236 9693 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   tokens: [CLS] us stocks - dow scales 30 , 000 on vaccine head ##way , bid ##en transition [SEP]\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23268 9539 2382 1010 2199 2006 17404 2132 4576 1010 7226 2368 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   tokens: [CLS] dow jones surge ##s above 30 , 000 , led by jp ##mo ##rgan , american express ; fed ##ex hits buy point [SEP]\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_ids: 101 23268 3557 12058 2015 2682 2382 1010 2199 1010 2419 2011 16545 5302 16998 1010 2137 4671 1025 7349 10288 4978 4965 2391 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   tokens: [CLS] tesla , nikola rally while chinese electric car stocks ve ##er off [SEP]\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_ids: 101 26060 1010 24794 8320 2096 2822 3751 2482 15768 2310 2121 2125 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   tokens: [CLS] us stocks - dow scales 30 , 000 on vaccine head ##way , bid ##en transition [SEP]\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23268 9539 2382 1010 2199 2006 17404 2132 4576 1010 7226 2368 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   tokens: [CLS] dow breaks key barrier as trump agrees to power transfer ; tesla among top performers [SEP]\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_ids: 101 23268 7807 3145 8803 2004 8398 10217 2000 2373 4651 1025 26060 2426 2327 9567 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   tokens: [CLS] us stocks - dow tops 30 , 000 on vaccine progress , bid ##en transition [SEP]\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23268 13284 2382 1010 2199 2006 17404 5082 1010 7226 2368 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   tokens: [CLS] new battery cells could give tesla semi more than 600 miles of range [SEP]\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_ids: 101 2047 6046 4442 2071 2507 26060 4100 2062 2084 5174 2661 1997 2846 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   tokens: [CLS] the dow hitting 30 , 000 may just be the start , hints investing legend [SEP]\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_ids: 101 1996 23268 7294 2382 1010 2199 2089 2074 2022 1996 2707 1010 20385 19920 5722 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   tokens: [CLS] here is the 4th most popular stock among hedge funds [SEP]\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_ids: 101 2182 2003 1996 4343 2087 2759 4518 2426 17834 5029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   tokens: [CLS] amazon workers in germany to go on strike on ' black friday ' [SEP]\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_ids: 101 9733 3667 1999 2762 2000 2175 2006 4894 2006 1005 2304 5958 1005 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   tokens: [CLS] tesla market cap surge ##s , topping $ 500 billion for first time [SEP]\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_ids: 101 26060 3006 6178 12058 2015 1010 22286 1002 3156 4551 2005 2034 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   tokens: [CLS] dow jones up 450 points , hits 30 , 000 as tesla gets extended [SEP]\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_ids: 101 23268 3557 2039 10332 2685 1010 4978 2382 1010 2199 2004 26060 4152 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   tokens: [CLS] top consumer discretion ##ary stocks for december 2020 [SEP]\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_ids: 101 2327 7325 19258 5649 15768 2005 2285 12609 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   tokens: [CLS] tesla ##s market cap zoom ##s past $ 500 billion [SEP]\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_ids: 101 26060 2015 3006 6178 24095 2015 2627 1002 3156 4551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   tokens: [CLS] how the bid ##en administration could benefit ev players in the us [SEP]\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_ids: 101 2129 1996 7226 2368 3447 2071 5770 23408 2867 1999 1996 2149 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   tokens: [CLS] us stocks - dow hits 30 , 000 on vaccine progress , bid ##en transition [SEP]\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23268 4978 2382 1010 2199 2006 17404 5082 1010 7226 2368 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   tokens: [CLS] dow jones jumps 500 points , as trump agrees to bid ##en transition ; ni ##o , tesla race to record highs [SEP]\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_ids: 101 23268 3557 14523 3156 2685 1010 2004 8398 10217 2000 7226 2368 6653 1025 9152 2080 1010 26060 2679 2000 2501 26836 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   tokens: [CLS] tesla passes $ 500 ##b market cap as s & p inclusion approaches [SEP]\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_ids: 101 26060 5235 1002 3156 2497 3006 6178 2004 1055 1004 1052 10502 8107 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   tokens: [CLS] why tesla stock jumped sharply on tuesday [SEP]\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_ids: 101 2339 26060 4518 5598 9249 2006 9857 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   tokens: [CLS] markets await ##s transition and economic data [SEP]\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_ids: 101 6089 26751 2015 6653 1998 3171 2951 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   tokens: [CLS] af ##firm deep dive [SEP]\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_ids: 101 21358 27972 2784 11529 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   tokens: [CLS] us stocks - dow hits all - time high on bid ##en transition , rebound hopes [SEP]\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23268 4978 2035 1011 2051 2152 2006 7226 2368 6653 1010 27755 8069 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   tokens: [CLS] tesla mu ##lls expanding in europe with compact vehicles : ceo [SEP]\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_ids: 101 26060 14163 12718 9186 1999 2885 2007 9233 4683 1024 5766 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   tokens: [CLS] transition , vaccines and retail sales make for a good week [SEP]\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_ids: 101 6653 1010 28896 1998 7027 4341 2191 2005 1037 2204 2733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   tokens: [CLS] auto stock round ##up : ts ##la to enter s & p 500 , gm to rev up ev investment & more [SEP]\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_ids: 101 8285 4518 2461 6279 1024 24529 2721 2000 4607 1055 1004 1052 3156 1010 13938 2000 7065 2039 23408 5211 1004 2062 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   tokens: [CLS] dow jones today leads early rally as gs ##a supports white house transition ; tesla stock leads e - auto rally [SEP]\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_ids: 101 23268 3557 2651 5260 2220 8320 2004 28177 2050 6753 2317 2160 6653 1025 26060 4518 5260 1041 1011 8285 8320 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   tokens: [CLS] tesla hits $ 500 billion mark after soaring 54 ##7 % this year [SEP]\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_ids: 101 26060 4978 1002 3156 4551 2928 2044 23990 5139 2581 1003 2023 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   tokens: [CLS] ni ##o ' s market cap just passed general motors : can it live up to its valuation ? [SEP]\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_ids: 101 9152 2080 1005 1055 3006 6178 2074 2979 2236 9693 1024 2064 2009 2444 2039 2000 2049 26004 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   tokens: [CLS] tesla ' s el ##on mu ##sk is now the world ' s second - richest person [SEP]\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_ids: 101 26060 1005 1055 3449 2239 14163 6711 2003 2085 1996 2088 1005 1055 2117 1011 18429 2711 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   tokens: [CLS] us stocks - wall st poised to jump on bid ##en transition , rebound hopes [SEP]\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 2813 2358 22303 2000 5376 2006 7226 2368 6653 1010 27755 8069 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   tokens: [CLS] tesla ( ts ##la ) to pro ##cure batteries from l ##g che ##m for model y [SEP]\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_ids: 101 26060 1006 24529 2721 1007 2000 4013 23887 10274 2013 1048 2290 18178 2213 2005 2944 1061 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   tokens: [CLS] amazon workers in germany to go on strike on \" black friday \" [SEP]\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_ids: 101 9733 3667 1999 2762 2000 2175 2006 4894 2006 1000 2304 5958 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   tokens: [CLS] dow jones futures : latest bit ##co ##in play in buy zone as tesla , ni ##o , xp ##eng fly ; apple stock breaks support [SEP]\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_ids: 101 23268 3557 17795 1024 6745 2978 3597 2378 2377 1999 4965 4224 2004 26060 1010 9152 2080 1010 26726 13159 4875 1025 6207 4518 7807 2490 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   tokens: [CLS] el ##on mu ##sk , janet yell ##en , general motors , best buy - 5 things you must know tuesday [SEP]\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_ids: 101 3449 2239 14163 6711 1010 9965 14315 2368 1010 2236 9693 1010 2190 4965 1011 1019 2477 2017 2442 2113 9857 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   tokens: [CLS] tesla set to breach $ 500 billion in market value [SEP]\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_ids: 101 26060 2275 2000 12510 1002 3156 4551 1999 3006 3643 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   tokens: [CLS] tesla market value crosses $ 500 billion as shares surge six - fold this year [SEP]\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_ids: 101 26060 3006 3643 7821 1002 3156 4551 2004 6661 12058 2416 1011 10671 2023 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   tokens: [CLS] why do baby boom ##ers hate tesla ? [SEP]\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_ids: 101 2339 2079 3336 8797 2545 5223 26060 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   tokens: [CLS] tesla ##s stock powered up to a record as wed ##bush analyst raised bull - case target to $ 1 , 000 [SEP]\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_ids: 101 26060 2015 4518 6113 2039 2000 1037 2501 2004 21981 22427 12941 2992 7087 1011 2553 4539 2000 1002 1015 1010 2199 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   tokens: [CLS] el ##on mu ##sk sur ##pass ##es bill gates to become world ' s second richest [SEP]\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_ids: 101 3449 2239 14163 6711 7505 15194 2229 3021 6733 2000 2468 2088 1005 1055 2117 18429 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   tokens: [CLS] tesla f ##sd beta 5 coming in few days with significant improvement , mu ##sk says [SEP]\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_ids: 101 26060 1042 16150 8247 1019 2746 1999 2261 2420 2007 3278 7620 1010 14163 6711 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   tokens: [CLS] tesla rolls out firm ##ware update after hacker discovers model x security flaw [SEP]\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_ids: 101 26060 9372 2041 3813 8059 10651 2044 23307 9418 2944 1060 3036 28450 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   tokens: [CLS] el ##on mu ##sk is now worlds second - richest person , as net worth has grown more than $ 100 billion this year [SEP]\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_ids: 101 3449 2239 14163 6711 2003 2085 8484 2117 1011 18429 2711 1010 2004 5658 4276 2038 4961 2062 2084 1002 2531 4551 2023 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   tokens: [CLS] a stock traders guide to black friday in the co ##vid - 19 era [SEP]\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_ids: 101 1037 4518 13066 5009 2000 2304 5958 1999 1996 2522 17258 1011 2539 3690 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   tokens: [CLS] security robots of the future and investing in ma ##as : join knights ##cope ceo william li for fires ##ide chat on dec . 9 [SEP]\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_ids: 101 3036 13507 1997 1996 2925 1998 19920 1999 5003 3022 1024 3693 7307 16186 5766 2520 5622 2005 8769 5178 11834 2006 11703 1012 1023 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   tokens: [CLS] tesla stock to $ 1 , 000 ? [SEP]\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_ids: 101 26060 4518 2000 1002 1015 1010 2199 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   tokens: [CLS] think the model s is fast ? [SEP]\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_ids: 101 2228 1996 2944 1055 2003 3435 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   tokens: [CLS] tesla stock could surge 104 % to $ 1 , 000 , according to this analyst [SEP]\n","11/26/2020 22:33:15 - INFO - finbert.utils -   input_ids: 101 26060 4518 2071 12058 9645 1003 2000 1002 1015 1010 2199 1010 2429 2000 2023 12941 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   tokens: [CLS] u . s . markets rise on vaccine optimism [SEP]\n","11/26/2020 22:33:15 - INFO - finbert.utils -   input_ids: 101 1057 1012 1055 1012 6089 4125 2006 17404 27451 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   tokens: [CLS] tesla , align technology help nas ##da ##q investors smile [SEP]\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_ids: 101 26060 1010 25705 2974 2393 17235 2850 4160 9387 2868 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   tokens: [CLS] us stocks - cyclic ##al gains lift stocks , yell ##en news gives brief boost [SEP]\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23750 2389 12154 6336 15768 1010 14315 2368 2739 3957 4766 12992 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   tokens: [CLS] us stocks - cyclic ##al boost lifts stocks ; yell ##en news gives short bump [SEP]\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 23750 2389 12992 13695 15768 1025 14315 2368 2739 3957 2460 16906 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   tokens: [CLS] dow jones adds to gains , nas ##da ##q turns positive ; tesla stock at new high [SEP]\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_ids: 101 23268 3557 9909 2000 12154 1010 17235 2850 4160 4332 3893 1025 26060 4518 2012 2047 2152 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   tokens: [CLS] us stocks - stocks rise on cyclic ##al boost but mega ##cap ##s curb gains [SEP]\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 15768 4125 2006 23750 2389 12992 2021 13164 17695 2015 13730 12154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   tokens: [CLS] gm vs . ford : 5 reasons why one is pulling ahead on electric cars [SEP]\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_ids: 101 13938 5443 1012 4811 1024 1019 4436 2339 2028 2003 4815 3805 2006 3751 3765 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   tokens: [CLS] blink charging ##s stock nearly triple ##s in 6 days amid a great deal of market interest in the ev sector [SEP]\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_ids: 101 12373 13003 2015 4518 3053 6420 2015 1999 1020 2420 13463 1037 2307 3066 1997 3006 3037 1999 1996 23408 4753 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   tokens: [CLS] tesla ( ts ##la ) will be part of the s & p 500 come december [SEP]\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_ids: 101 26060 1006 24529 2721 1007 2097 2022 2112 1997 1996 1055 1004 1052 3156 2272 2285 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   tokens: [CLS] tesla def ##ies doubt ##ers as builds on rally ahead of s & p 500 debut [SEP]\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_ids: 101 26060 13366 3111 4797 2545 2004 16473 2006 8320 3805 1997 1055 1004 1052 3156 2834 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   tokens: [CLS] short - sellers disappear as market gains to start shortened holiday week [SEP]\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_ids: 101 2460 1011 19041 10436 2004 3006 12154 2000 2707 12641 6209 2733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   tokens: [CLS] us stocks - energy , industrial ##s prop up dow ; tech mega - caps slide [SEP]\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_ids: 101 2149 15768 1011 2943 1010 3919 2015 17678 2039 23268 1025 6627 13164 1011 9700 7358 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:19 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:19 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:19 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   tokens: [CLS] is tesla stock a buy right now ? [SEP]\n","11/26/2020 22:33:19 - INFO - finbert.utils -   input_ids: 101 2003 26060 4518 1037 4965 2157 2085 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:19 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:19 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:19 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   tokens: [CLS] dow jones leads as stock market trim ##s gains ; apple falls but tesla , ni ##o surge [SEP]\n","11/26/2020 22:33:19 - INFO - finbert.utils -   input_ids: 101 23268 3557 5260 2004 4518 3006 12241 2015 12154 1025 6207 4212 2021 26060 1010 9152 2080 12058 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:19 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:20 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:20 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:20 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   tokens: [CLS] dow jones jumps 300 points on vaccine news , but apple slides ; tesla surge ##s to record high , while ni ##o races higher [SEP]\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_ids: 101 23268 3557 14523 3998 2685 2006 17404 2739 1010 2021 6207 14816 1025 26060 12058 2015 2000 2501 2152 1010 2096 9152 2080 3837 3020 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:20 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:20 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:20 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   tokens: [CLS] the epa says the ford mustang mach - e ' s electric range is a lack ##lus ##ter 211 - 300 miles [SEP]\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_ids: 101 1996 19044 2758 1996 4811 18851 24532 1011 1041 1005 1055 3751 2846 2003 1037 3768 7393 3334 19235 1011 3998 2661 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:20 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:20 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:20 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   tokens: [CLS] why tesla stock jumped 7 % early today [SEP]\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_ids: 101 2339 26060 4518 5598 1021 1003 2220 2651 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:20 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:20 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:20 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   tokens: [CLS] amazon to give $ 500 million in holiday bonuses to front - line u . s . workers [SEP]\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_ids: 101 9733 2000 2507 1002 3156 2454 1999 6209 29563 2000 2392 1011 2240 1057 1012 1055 1012 3667 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:20 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:21 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:21 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:21 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   tokens: [CLS] gift guide : 7 smart home gift ideas that go beyond the usual google / amazon smart speakers [SEP]\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_ids: 101 5592 5009 1024 1021 6047 2188 5592 4784 2008 2175 3458 1996 5156 8224 1013 9733 6047 7492 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:21 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:21 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:21 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   tokens: [CLS] gdp ##r enforcement must level up to catch big tech , report warns [SEP]\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_ids: 101 14230 2099 7285 2442 2504 2039 2000 4608 2502 6627 1010 3189 19428 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:21 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:21 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:21 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   tokens: [CLS] 10 stocks to be thankful for this thanksgiving [SEP]\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_ids: 101 2184 15768 2000 2022 18836 2005 2023 15060 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:21 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:22 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:22 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:22 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   tokens: [CLS] if you have $ 1 , 000 and 10 years to wait , buy these 2 stocks now [SEP]\n","11/26/2020 22:33:22 - INFO - finbert.utils -   input_ids: 101 2065 2017 2031 1002 1015 1010 2199 1998 2184 2086 2000 3524 1010 4965 2122 1016 15768 2085 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:22 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:22 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:22 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   tokens: [CLS] the s & p 500 could jump 20 % next year . [SEP]\n","11/26/2020 22:33:22 - INFO - finbert.utils -   input_ids: 101 1996 1055 1004 1052 3156 2071 5376 2322 1003 2279 2095 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:22 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:22 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:23 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:23 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   tokens: [CLS] 5 perfect stocks to go ##bble up right now [SEP]\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_ids: 101 1019 3819 15768 2000 2175 11362 2039 2157 2085 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:23 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:23 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:23 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   tokens: [CLS] forget the bargain basement . [SEP]\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_ids: 101 5293 1996 17113 8102 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:23 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:23 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:23 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   tokens: [CLS] big oil and big tech are spending billions on renewable energy [SEP]\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_ids: 101 2502 3514 1998 2502 6627 2024 5938 25501 2006 13918 2943 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:23 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:24 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:24 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   tokens: [CLS] amazon cloud out ##age hits customers including ro ##ku , adobe [SEP]\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_ids: 101 9733 6112 2041 4270 4978 6304 2164 20996 5283 1010 18106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:24 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:24 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   tokens: [CLS] why mara ##don ##a was better than mess ##i and ronald ##o [SEP]\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_ids: 101 2339 13955 5280 2050 2001 2488 2084 6752 2072 1998 8923 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:24 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:24 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   tokens: [CLS] sales ##force acquisition of slack could trigger m & a wave , analyst says [SEP]\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_ids: 101 4341 14821 7654 1997 19840 2071 9495 1049 1004 1037 4400 1010 12941 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:24 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:24 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:24 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   tokens: [CLS] amazon cloud out ##age hits customers including ro ##ku , adobe [SEP]\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_ids: 101 9733 6112 2041 4270 4978 6304 2164 20996 5283 1010 18106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:25 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:25 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:25 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   tokens: [CLS] what will tomorrow ' s tech look like ? [SEP]\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_ids: 101 2054 2097 4826 1005 1055 6627 2298 2066 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:25 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:25 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:25 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   tokens: [CLS] amazon web services suffers amid widespread issues with online applications [SEP]\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_ids: 101 9733 4773 2578 17567 13463 6923 3314 2007 3784 5097 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:25 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:26 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:26 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:26 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   tokens: [CLS] self - driving - car firm way ##mo sharpe ##ns co ##vid worker - safety rules [SEP]\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_ids: 101 2969 1011 4439 1011 2482 3813 2126 5302 22147 3619 2522 17258 7309 1011 3808 3513 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:26 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:26 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:26 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   tokens: [CLS] look ##back : tao values 2019 alphabet inc ( goo ##g ) thesis [SEP]\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_ids: 101 2298 5963 1024 20216 5300 10476 12440 4297 1006 27571 2290 1007 9459 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:26 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:26 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:26 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   tokens: [CLS] hp ceo : co ##vid - 19 pan ##de ##mic has reinforced our consumer business [SEP]\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_ids: 101 6522 5766 1024 2522 17258 1011 2539 6090 3207 7712 2038 11013 2256 7325 2449 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:26 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:26 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:26 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   tokens: [CLS] why upcoming ip ##o rob ##lo ##x could become the youtube of gaming [SEP]\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_ids: 101 2339 9046 12997 2080 6487 4135 2595 2071 2468 1996 7858 1997 10355 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:26 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:27 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:27 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   tokens: [CLS] colin ka ##ep ##ern ##ick will not play in the nfl again : emmanuel ac ##ho [SEP]\n","11/26/2020 22:33:27 - INFO - finbert.utils -   input_ids: 101 6972 10556 13699 11795 6799 2097 2025 2377 1999 1996 5088 2153 1024 14459 9353 6806 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:27 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:27 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   tokens: [CLS] france def ##ies u . s . and starts levy ##ing digital tax on tech giants . [SEP]\n","11/26/2020 22:33:27 - INFO - finbert.utils -   input_ids: 101 2605 13366 3111 1057 1012 1055 1012 1998 4627 12767 2075 3617 4171 2006 6627 7230 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:27 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:28 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:28 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:28 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   tokens: [CLS] hedge funds are finally beating the market in 2020 . [SEP]\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_ids: 101 17834 5029 2024 2633 6012 1996 3006 1999 12609 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:28 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:28 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:28 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   tokens: [CLS] amazon ( am ##z ##n ) cloud client ##ele improves as za ##land ##o picks aw ##s [SEP]\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_ids: 101 9733 1006 2572 2480 2078 1007 6112 7396 12260 24840 2004 23564 3122 2080 11214 22091 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:28 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:28 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:28 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   tokens: [CLS] amazon ##s aw ##s was hit by out ##ages . [SEP]\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_ids: 101 9733 2015 22091 2015 2001 2718 2011 2041 13923 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:28 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:29 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:29 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   tokens: [CLS] equal - weighted index ##es are winning ##and that ##s a good sign for stocks [SEP]\n","11/26/2020 22:33:29 - INFO - finbert.utils -   input_ids: 101 5020 1011 18215 5950 2229 2024 3045 5685 2008 2015 1037 2204 3696 2005 15768 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:29 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:29 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   tokens: [CLS] google thinking of 202 ##3 with its gaming service st ##adia as war with fellow tech giants heats up [SEP]\n","11/26/2020 22:33:29 - INFO - finbert.utils -   input_ids: 101 8224 3241 1997 16798 2509 2007 2049 10355 2326 2358 25205 2004 2162 2007 3507 6627 7230 18559 2039 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:29 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:30 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:30 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   tokens: [CLS] south korea un ##ve ##ils ai chip to maintain semiconductor leadership [SEP]\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_ids: 101 2148 4420 4895 3726 12146 9932 9090 2000 5441 20681 4105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:30 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:30 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   tokens: [CLS] air ##bn ##b prepares to ip ##o [SEP]\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_ids: 101 2250 24700 2497 20776 2000 12997 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:30 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:30 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   tokens: [CLS] youtube ban ##s one america news network from posting new videos for a week [SEP]\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_ids: 101 7858 7221 2015 2028 2637 2739 2897 2013 14739 2047 6876 2005 1037 2733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:30 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:30 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   tokens: [CLS] youtube suspend ##s o ##an , a trump favorite , for to ##uting co ##vid cure [SEP]\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_ids: 101 7858 28324 2015 1051 2319 1010 1037 8398 5440 1010 2005 2000 20807 2522 17258 9526 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:30 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:31 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:31 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:31 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   tokens: [CLS] senators ask youtube to remove election mis ##in ##form ##ation [SEP]\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_ids: 101 10153 3198 7858 2000 6366 2602 28616 2378 14192 3370 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:31 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:31 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:31 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   tokens: [CLS] google reportedly wants to buy indian social media firm share ##cha ##t [SEP]\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_ids: 101 8224 7283 4122 2000 4965 2796 2591 2865 3813 3745 7507 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:31 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:31 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:31 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   tokens: [CLS] google back in buy zone [SEP]\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_ids: 101 8224 2067 1999 4965 4224 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:31 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:32 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:32 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:32 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   tokens: [CLS] look ##back : wedge ##wood partners 2019 alphabet inc ( goo ##gl ) thesis [SEP]\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_ids: 101 2298 5963 1024 17632 3702 5826 10476 12440 4297 1006 27571 23296 1007 9459 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:32 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:32 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:32 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   tokens: [CLS] amazon web services out ##age disrupt ##s internet [SEP]\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_ids: 101 9733 4773 2578 2041 4270 23217 2015 4274 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:32 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:32 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:32 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   tokens: [CLS] apple ( aa ##pl ) seeks tough data protection in google lawsuit [SEP]\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_ids: 101 6207 1006 9779 24759 1007 11014 7823 2951 3860 1999 8224 9870 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:32 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:32 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:32 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   tokens: [CLS] hyper ##bolic to compare unpaid college sports to slavery : emmanuel ac ##ho [SEP]\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_ids: 101 23760 18647 2000 12826 23850 2267 2998 2000 8864 1024 14459 9353 6806 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:32 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:33 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:33 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:33 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   tokens: [CLS] tech giants ask malaysia pm to reins ##tate foreign ship cable wai ##ver : report [SEP]\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_ids: 101 6627 7230 3198 6027 7610 2000 19222 12259 3097 2911 5830 23701 6299 1024 3189 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:33 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:33 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:33 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   tokens: [CLS] uber for trucks man ##bang piles on another $ 1 . 7 ##b funding over google , soft ##bank ' s , ahead of highly - anticipated ip ##o [SEP]\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_ids: 101 19169 2005 9322 2158 25153 18526 2006 2178 1002 1015 1012 1021 2497 4804 2058 8224 1010 3730 9299 1005 1055 1010 3805 1997 3811 1011 11436 12997 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:33 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:33 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:33 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   tokens: [CLS] soft ##bank - led round values uber - like truck startup at $ 12 billion [SEP]\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_ids: 101 3730 9299 1011 2419 2461 5300 19169 1011 2066 4744 22752 2012 1002 2260 4551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:33 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:34 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:34 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   tokens: [CLS] u . s . states prepare second anti ##trust lawsuit against google for december [SEP]\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_ids: 101 1057 1012 1055 1012 2163 7374 2117 3424 24669 9870 2114 8224 2005 2285 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:34 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:34 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   tokens: [CLS] u . s . states prep ##ping second anti ##trust lawsuit against google for next month [SEP]\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_ids: 101 1057 1012 1055 1012 2163 17463 4691 2117 3424 24669 9870 2114 8224 2005 2279 3204 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:34 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:34 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   tokens: [CLS] morgan stanley ##s lynch wins big on growth bets [SEP]\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_ids: 101 5253 6156 2015 11404 5222 2502 2006 3930 29475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:34 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:35 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:35 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:35 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   tokens: [CLS] google ##s new advertising technology is under the regulatory microscope after a group of businesses called for it to be legally blocked [SEP]\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_ids: 101 8224 2015 2047 6475 2974 2003 2104 1996 10738 24635 2044 1037 2177 1997 5661 2170 2005 2009 2000 2022 10142 8534 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:35 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:35 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:35 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   tokens: [CLS] google cloud is creating a new type of digital banking platform with this lend ##er [SEP]\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_ids: 101 8224 6112 2003 4526 1037 2047 2828 1997 3617 8169 4132 2007 2023 18496 2121 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:35 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:35 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:35 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   tokens: [CLS] the zack ##s analyst blog highlights : ali ##ba ##ba and amazon [SEP]\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_ids: 101 1996 13658 2015 12941 9927 11637 1024 4862 3676 3676 1998 9733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:35 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:36 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:36 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:36 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   tokens: [CLS] why ro ##ku stock jumped on monday [SEP]\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_ids: 101 2339 20996 5283 4518 5598 2006 6928 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:36 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:36 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:36 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   tokens: [CLS] dow rallies as investors cheer possible return of yell ##en , vaccine news [SEP]\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_ids: 101 23268 22867 2004 9387 15138 2825 2709 1997 14315 2368 1010 17404 2739 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:36 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:36 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:36 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   tokens: [CLS] russia opens case against google , saying it failed to del ##ete banned content [SEP]\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_ids: 101 3607 7480 2553 2114 8224 1010 3038 2009 3478 2000 3972 12870 7917 4180 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:36 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:37 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:37 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:37 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   tokens: [CLS] dow rallies on news bid ##en to pick yell ##en as treasury secretary [SEP]\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_ids: 101 23268 22867 2006 2739 7226 2368 2000 4060 14315 2368 2004 9837 3187 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:37 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:37 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:37 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   tokens: [CLS] google brings ' the mandal ##oria ##n ' to ar in its new app [SEP]\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_ids: 101 8224 7545 1005 1996 24373 11069 2078 1005 2000 12098 1999 2049 2047 10439 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:37 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:37 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:37 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   tokens: [CLS] snap to pay $ 1 million a day to creators for spotlight videos [SEP]\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_ids: 101 10245 2000 3477 1002 1015 2454 1037 2154 2000 17277 2005 17763 6876 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:37 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:37 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:37 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   tokens: [CLS] digital marketing firms file uk competition complaint against google ' s privacy sand ##box [SEP]\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_ids: 101 3617 5821 9786 5371 2866 2971 12087 2114 8224 1005 1055 9394 5472 8758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:37 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:38 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:38 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:38 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   tokens: [CLS] google ad changes targeted by rivals in u . k . complaint [SEP]\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_ids: 101 8224 4748 3431 9416 2011 9169 1999 1057 1012 1047 1012 12087 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:38 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:38 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:38 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   tokens: [CLS] fox ##con ##n plant championed by trump lands google server contract [SEP]\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_ids: 101 4419 8663 2078 3269 28683 2011 8398 4915 8224 8241 3206 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:38 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:38 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:38 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   tokens: [CLS] influence ##rs with andy ser ##wer : emmanuel ac ##ho [SEP]\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_ids: 101 3747 2869 2007 5557 14262 13777 1024 14459 9353 6806 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:38 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:39 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:39 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:39 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   tokens: [CLS] sales ##force acquisition of slack could trigger m & a wave , analyst says [SEP]\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_ids: 101 4341 14821 7654 1997 19840 2071 9495 1049 1004 1037 4400 1010 12941 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:39 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:39 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:39 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   tokens: [CLS] emmanuel ac ##ho : donald trump can ##t di ##cta ##te the perception of the nfl [SEP]\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_ids: 101 14459 9353 6806 1024 6221 8398 2064 2102 4487 25572 2618 1996 10617 1997 1996 5088 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:39 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:39 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:39 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   tokens: [CLS] google under review for possible british competition en ##qui ##ry [SEP]\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_ids: 101 8224 2104 3319 2005 2825 2329 2971 4372 15549 2854 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:39 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:39 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:40 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:40 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   tokens: [CLS] uk ' s competition regulator looking at formal investigation into google [SEP]\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_ids: 101 2866 1005 1055 2971 21618 2559 2012 5337 4812 2046 8224 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:40 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:40 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:40 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   tokens: [CLS] these stocks would have doubled your money last year [SEP]\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_ids: 101 2122 15768 2052 2031 11515 2115 2769 2197 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:40 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:40 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:40 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   tokens: [CLS] matthew mcc ##ona ##ugh ##ey : social media has been good for business [SEP]\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_ids: 101 5487 23680 7856 8953 3240 1024 2591 2865 2038 2042 2204 2005 2449 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:40 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:40 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:40 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   tokens: [CLS] up over 250 % in 2020 , is pin ##ter ##est stock still a buy ? [SEP]\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_ids: 101 2039 2058 5539 1003 1999 12609 1010 2003 9231 3334 4355 4518 2145 1037 4965 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:40 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:41 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:41 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:41 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   tokens: [CLS] ko ##mine ##rs ##s con ##und ##rum ##s : country music can save the world [SEP]\n","11/26/2020 22:33:41 - INFO - finbert.utils -   input_ids: 101 12849 11233 2869 2015 9530 8630 6824 2015 1024 2406 2189 2064 3828 1996 2088 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:41 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:41 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:41 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   tokens: [CLS] this digital health startup has joined forces with amazon and nike . [SEP]\n","11/26/2020 22:33:41 - INFO - finbert.utils -   input_ids: 101 2023 3617 2740 22752 2038 2587 2749 2007 9733 1998 18368 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:41 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:41 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:42 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:42 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   tokens: [CLS] matthew mcc ##ona ##ugh ##ey explains why he ##s inspired by marc ben ##io ##ff ' s ' new capitalism ' [SEP]\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_ids: 101 5487 23680 7856 8953 3240 7607 2339 2002 2015 4427 2011 7871 3841 3695 4246 1005 1055 1005 2047 16498 1005 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:42 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:42 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:42 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   tokens: [CLS] western union grabs 15 % stake in saudi digital payments business [SEP]\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_ids: 101 2530 2586 13273 2321 1003 8406 1999 8174 3617 10504 2449 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:42 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:42 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:42 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   tokens: [CLS] tv shows you should bing ##e watch this holiday weekend [SEP]\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_ids: 101 2694 3065 2017 2323 17620 2063 3422 2023 6209 5353 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:42 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:42 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:42 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   tokens: [CLS] the cloud , ai and the transformation of retail [SEP]\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_ids: 101 1996 6112 1010 9932 1998 1996 8651 1997 7027 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:42 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:43 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:43 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:43 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   tokens: [CLS] apple to at & t wary of full disclosure in google anti ##trust case [SEP]\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_ids: 101 6207 2000 2012 1004 1056 15705 1997 2440 19380 1999 8224 3424 24669 2553 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:43 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:43 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:43 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   tokens: [CLS] apple , group ##m , others ask for tough protection for data in google lawsuit [SEP]\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_ids: 101 6207 1010 2177 2213 1010 2500 3198 2005 7823 3860 2005 2951 1999 8224 9870 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:43 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:43 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:43 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   tokens: [CLS] apple , at & t ask for tough protection for data in google lawsuit [SEP]\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_ids: 101 6207 1010 2012 1004 1056 3198 2005 7823 3860 2005 2951 1999 8224 9870 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:43 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:44 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:44 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:44 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   tokens: [CLS] blind man , ' born to run , ' completes solo 5 ##k with trial app to guide him [SEP]\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_ids: 101 6397 2158 1010 1005 2141 2000 2448 1010 1005 28123 3948 1019 2243 2007 3979 10439 2000 5009 2032 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:44 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:44 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:44 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   tokens: [CLS] corrected - blind man , ' born to run , ' completes solo 5 ##k with trial app to guide him [SEP]\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_ids: 101 13371 1011 6397 2158 1010 1005 2141 2000 2448 1010 1005 28123 3948 1019 2243 2007 3979 10439 2000 5009 2032 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:44 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:44 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:44 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   tokens: [CLS] alphabet could rally $ 100 according to the charts [SEP]\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_ids: 101 12440 2071 8320 1002 2531 2429 2000 1996 6093 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:44 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:44 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:44 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   tokens: [CLS] 3 stocks continuing to shine in the over ##val ##ue ##d internet services industry [SEP]\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_ids: 101 1017 15768 5719 2000 12342 1999 1996 2058 10175 5657 2094 4274 2578 3068 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:44 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:45 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:45 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   tokens: [CLS] twitter stock has been an eyes ##ore , but fleets could change that [SEP]\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_ids: 101 10474 4518 2038 2042 2019 2159 5686 1010 2021 25515 2071 2689 2008 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:45 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:45 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   tokens: [CLS] facebook and twitter en ##rage users as ' a fantastic way ' to sell ads : nyu professor scott galloway [SEP]\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_ids: 101 9130 1998 10474 4372 24449 5198 2004 1005 1037 10392 2126 1005 2000 5271 14997 1024 27935 2934 3660 22372 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:45 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:45 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   tokens: [CLS] corona ##virus surge and no stimulus will result in empty store ##front ##s nationwide [SEP]\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_ids: 101 21887 23350 12058 1998 2053 19220 2097 2765 1999 4064 3573 12792 2015 9053 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:45 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:46 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:46 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   tokens: [CLS] google , facebook and twitter threaten to leave pakistan over censorship law [SEP]\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_ids: 101 8224 1010 9130 1998 10474 15686 2000 2681 4501 2058 15657 2375 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:46 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:46 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   tokens: [CLS] google to pay some french publishers for content [SEP]\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_ids: 101 8224 2000 3477 2070 2413 8544 2005 4180 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:46 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:46 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   tokens: [CLS] here ' s my tech run ##down , brazilian - style [SEP]\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_ids: 101 2182 1005 1055 2026 6627 2448 7698 1010 6142 1011 2806 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:46 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:47 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   tokens: [CLS] the stocks the pro ##s own usually beat the market . [SEP]\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_ids: 101 1996 15768 1996 4013 2015 2219 2788 3786 1996 3006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:47 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   tokens: [CLS] 30 richest cities in the united states [SEP]\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_ids: 101 2382 18429 3655 1999 1996 2142 2163 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:47 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:47 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:47 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   tokens: [CLS] ' live anywhere ' : how air ##bn ##b is surviving co ##vid - 19 [SEP]\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_ids: 101 1005 2444 5973 1005 1024 2129 2250 24700 2497 2003 6405 2522 17258 1011 2539 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:47 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   tokens: [CLS] the zack ##s analyst blog highlights : google , microsoft , texas instruments , n ##vid ##ia and sky ##works solutions [SEP]\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_ids: 101 1996 13658 2015 12941 9927 11637 1024 8224 1010 7513 1010 3146 5693 1010 1050 17258 2401 1998 3712 9316 7300 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   tokens: [CLS] this top - performing mutual fund shu ##ns apple , facebook , netflix [SEP]\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_ids: 101 2023 2327 1011 4488 8203 4636 18454 3619 6207 1010 9130 1010 20907 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:48 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:48 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   tokens: [CLS] analyst sees snap hitting $ 200 ##b valuation by 202 ##5 [SEP]\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_ids: 101 12941 5927 10245 7294 1002 3263 2497 26004 2011 16798 2629 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:48 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   tokens: [CLS] graphic - french , italian economies hurt most under second lock ##down ##s [SEP]\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_ids: 101 8425 1011 2413 1010 3059 18730 3480 2087 2104 2117 5843 7698 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   tokens: [CLS] black friday will be great for shop ##pers . [SEP]\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_ids: 101 2304 5958 2097 2022 2307 2005 4497 7347 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:49 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:49 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   tokens: [CLS] rob ##lo ##x files for ny ##se ip ##o as user ##base grows 82 % in 2020 [SEP]\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_ids: 101 6487 4135 2595 6764 2005 6396 3366 12997 2080 2004 5310 15058 7502 6445 1003 1999 12609 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:49 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   tokens: [CLS] robot ##ax ##i companies get the green light to charge for rides in california [SEP]\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_ids: 101 8957 8528 2072 3316 2131 1996 2665 2422 2000 3715 2005 12271 1999 2662 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   tokens: [CLS] robot ##ax ##i companies can now win approval to operate in california [SEP]\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_ids: 101 8957 8528 2072 3316 2064 2085 2663 6226 2000 5452 1999 2662 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:50 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:50 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   tokens: [CLS] twitter ##s jack dorsey should be fired for being ceo of 2 firms : big tech critic scott galloway [SEP]\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_ids: 101 10474 2015 2990 27332 2323 2022 5045 2005 2108 5766 1997 1016 9786 1024 2502 6627 6232 3660 22372 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:50 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   tokens: [CLS] thank you , chrome team [SEP]\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_ids: 101 4067 2017 1010 18546 2136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   tokens: [CLS] black friday 2020 : tips for buying the best tech gifts [SEP]\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_ids: 101 2304 5958 12609 1024 10247 2005 9343 1996 2190 6627 9604 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   tokens: [CLS] new contact tracing apps stir hope for virus fighters in u . s . states [SEP]\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_ids: 101 2047 3967 16907 18726 16130 3246 2005 7865 7299 1999 1057 1012 1055 1012 2163 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:51 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:51 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:51 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   tokens: [CLS] tech in the bid ##en era [SEP]\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_ids: 101 6627 1999 1996 7226 2368 3690 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:51 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:52 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:52 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   tokens: [CLS] google st ##adia will be available for ios soon [SEP]\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_ids: 101 8224 2358 25205 2097 2022 2800 2005 16380 2574 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:52 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:52 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   tokens: [CLS] rev ##amp ##ed google pay targets pay ##pal , ve ##n ##mo , and apple pay [SEP]\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_ids: 101 7065 16613 2098 8224 3477 7889 3477 12952 1010 2310 2078 5302 1010 1998 6207 3477 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:52 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:52 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   tokens: [CLS] via ##com ##cb ##s is selling its book publisher for $ 2 . 2 billion . [SEP]\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_ids: 101 3081 9006 27421 2015 2003 4855 2049 2338 6674 2005 1002 1016 1012 1016 4551 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:52 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   tokens: [CLS] son ##os ceo on sky ##rock ##eti ##ng stock price : ' we have an in ##fle ##ction point ' [SEP]\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_ids: 101 2365 2891 5766 2006 3712 16901 20624 3070 4518 3976 1024 1005 2057 2031 2019 1999 21031 7542 2391 1005 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   tokens: [CLS] google pay product manager on ' pl ##ex account ' launch [SEP]\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_ids: 101 8224 3477 4031 3208 2006 1005 20228 10288 4070 1005 4888 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:53 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:53 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   tokens: [CLS] tech support : what to buy on black friday [SEP]\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_ids: 101 6627 2490 1024 2054 2000 4965 2006 2304 5958 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:53 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   tokens: [CLS] google plans to test end - to - end encryption in android messages [SEP]\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_ids: 101 8224 3488 2000 3231 2203 1011 2000 1011 2203 21999 1999 11924 7696 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   tokens: [CLS] dow cuts losses on tech strength , stimulus hopes [SEP]\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_ids: 101 23268 7659 6409 2006 6627 3997 1010 19220 8069 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:54 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:54 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   tokens: [CLS] son ##oss blow ##out quarter and ambitious outlook has wall street gus ##hing . [SEP]\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_ids: 101 2365 15094 6271 5833 4284 1998 12479 17680 2038 2813 2395 12670 12053 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:54 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:55 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:55 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:55 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   tokens: [CLS] google signs copyright agreements with six french newspapers [SEP]\n","11/26/2020 22:33:55 - INFO - finbert.utils -   input_ids: 101 8224 5751 9385 10540 2007 2416 2413 6399 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:55 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:55 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:55 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   tokens: [CLS] google signs copyright agreement with six french newspapers [SEP]\n","11/26/2020 22:33:55 - INFO - finbert.utils -   input_ids: 101 8224 5751 9385 3820 2007 2416 2413 6399 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:55 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   tokens: [CLS] better buy : bai ##du vs . [SEP]\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_ids: 101 2488 4965 1024 21790 8566 5443 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   tokens: [CLS] 5 tech giants to buy at deep discount amid recent turmoil [SEP]\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_ids: 101 1019 6627 7230 2000 4965 2012 2784 19575 13463 3522 17930 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:56 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:56 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:56 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   tokens: [CLS] amazon to give $ 500 million in holiday bonuses to front - line u . s . workers [SEP]\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_ids: 101 9733 2000 2507 1002 3156 2454 1999 6209 29563 2000 2392 1011 2240 1057 1012 1055 1012 3667 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:56 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:57 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:57 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:57 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   tokens: [CLS] amazon web services out ##age takes a portion of the internet down with it [SEP]\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_ids: 101 9733 4773 2578 2041 4270 3138 1037 4664 1997 1996 4274 2091 2007 2009 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:57 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:57 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:57 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   tokens: [CLS] amazon web services suffers amid widespread issues with online applications [SEP]\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_ids: 101 9733 4773 2578 17567 13463 6923 3314 2007 3784 5097 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:57 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:57 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:57 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   tokens: [CLS] amazon ' s ( am ##z ##n ) aw ##s adds amazon mw ##aa to services portfolio [SEP]\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_ids: 101 9733 1005 1055 1006 2572 2480 2078 1007 22091 2015 9909 9733 12464 11057 2000 2578 11103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:57 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   tokens: [CLS] ana ##pl ##an ( plan ) q ##3 loss narrower than expected , revenues up y / y [SEP]\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_ids: 101 9617 24759 2319 1006 2933 1007 1053 2509 3279 22546 2084 3517 1010 12594 2039 1061 1013 1061 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   tokens: [CLS] amazon merchants say deliveries of some products are delayed [SEP]\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_ids: 101 9733 10310 2360 23534 1997 2070 3688 2024 8394 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   tokens: [CLS] master ##card retail advisor on holiday shopping : its all about making consumers feel safe this year [SEP]\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_ids: 101 3040 11522 7027 8619 2006 6209 6023 1024 2049 2035 2055 2437 10390 2514 3647 2023 2095 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:58 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:58 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   tokens: [CLS] how much people are expected to spend this cyber monday [SEP]\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_ids: 101 2129 2172 2111 2024 3517 2000 5247 2023 16941 6928 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:58 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   tokens: [CLS] better buy : ali ##ba ##ba vs . amazon [SEP]\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_ids: 101 2488 4965 1024 4862 3676 3676 5443 1012 9733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   tokens: [CLS] ibm planning 10 , 000 job cuts in europe ahead of unit sale [SEP]\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_ids: 101 9980 4041 2184 1010 2199 3105 7659 1999 2885 3805 1997 3131 5096 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:33:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:33:59 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:33:59 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   tokens: [CLS] hp ceo : co ##vid - 19 pan ##de ##mic has reinforced our consumer business [SEP]\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_ids: 101 6522 5766 1024 2522 17258 1011 2539 6090 3207 7712 2038 11013 2256 7325 2449 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:33:59 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:00 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:00 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   tokens: [CLS] here ' s the critically important point investors missed about amazon ' s earnings [SEP]\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_ids: 101 2182 1005 1055 1996 11321 2590 2391 9387 4771 2055 9733 1005 1055 16565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:00 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:00 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   tokens: [CLS] orange ( or ##an ) teams up with amazon to opt ##imi ##ze aw ##s apps [SEP]\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_ids: 101 4589 1006 2030 2319 1007 2780 2039 2007 9733 2000 23569 27605 4371 22091 2015 18726 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:00 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:00 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:00 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   tokens: [CLS] 2 top stocks you can buy on sale [SEP]\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_ids: 101 1016 2327 15768 2017 2064 4965 2006 5096 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:00 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   tokens: [CLS] the 3 largest retail apocalypse - proof stocks in 2020 [SEP]\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_ids: 101 1996 1017 2922 7027 16976 1011 6947 15768 1999 12609 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   tokens: [CLS] colin ka ##ep ##ern ##ick will not play in the nfl again : emmanuel ac ##ho [SEP]\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_ids: 101 6972 10556 13699 11795 6799 2097 2025 2377 1999 1996 5088 2153 1024 14459 9353 6806 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:01 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:01 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:01 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   tokens: [CLS] france def ##ies u . s . and starts levy ##ing digital tax on tech giants . [SEP]\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_ids: 101 2605 13366 3111 1057 1012 1055 1012 1998 4627 12767 2075 3617 4171 2006 6627 7230 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:01 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   tokens: [CLS] hedge funds are finally beating the market in 2020 . [SEP]\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_ids: 101 17834 5029 2024 2633 6012 1996 3006 1999 12609 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   tokens: [CLS] 3 growth stocks to buy and hold for the next 50 years [SEP]\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_ids: 101 1017 3930 15768 2000 4965 1998 2907 2005 1996 2279 2753 2086 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:02 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:02 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   tokens: [CLS] french tax authorities have started demanding u . s . firms pay digital tax : report [SEP]\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_ids: 101 2413 4171 4614 2031 2318 9694 1057 1012 1055 1012 9786 3477 3617 4171 1024 3189 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:02 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   tokens: [CLS] is b ##j ' s wholesale club stock a buy ? [SEP]\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_ids: 101 2003 1038 3501 1005 1055 17264 2252 4518 1037 4965 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   tokens: [CLS] amazon canada ' s first sm ##b impact report highlights success for small and medium - sized businesses ; canadian sellers grossed more than $ 2 billion on amazon ' s stores around the world [SEP]\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_ids: 101 9733 2710 1005 1055 2034 15488 2497 4254 3189 11637 3112 2005 2235 1998 5396 1011 7451 5661 1025 3010 19041 17500 2062 2084 1002 1016 4551 2006 9733 1005 1055 5324 2105 1996 2088 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:03 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:03 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   tokens: [CLS] how x ##out capital picks retailers for its large - cap index fund [SEP]\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_ids: 101 2129 1060 5833 3007 11214 16629 2005 2049 2312 1011 6178 5950 4636 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:03 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   tokens: [CLS] amazon launches ip accelerator in europe to help small businesses protect their brands and tackle counter ##feit [SEP]\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_ids: 101 9733 18989 12997 23468 1999 2885 2000 2393 2235 5661 4047 2037 9639 1998 11147 4675 21156 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   tokens: [CLS] amazon ( am ##z ##n ) cloud client ##ele improves as za ##land ##o picks aw ##s [SEP]\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_ids: 101 9733 1006 2572 2480 2078 1007 6112 7396 12260 24840 2004 23564 3122 2080 11214 22091 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   tokens: [CLS] equal - weighted index ##es are winning ##and that ##s a good sign for stocks [SEP]\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_ids: 101 5020 1011 18215 5950 2229 2024 3045 5685 2008 2015 1037 2204 3696 2005 15768 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:04 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:04 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:04 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   tokens: [CLS] why good ##r ##x ##s ceo isn ##t worried about amazon pharmacy [SEP]\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_ids: 101 2339 2204 2099 2595 2015 5766 3475 2102 5191 2055 9733 13882 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:04 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   tokens: [CLS] big brother amazon targeted in retail fight with am ##ban ##i [SEP]\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_ids: 101 2502 2567 9733 9416 1999 7027 2954 2007 2572 8193 2072 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   tokens: [CLS] french tax authorities nu ##dge amazon , facebook to shell out digital tax : ft [SEP]\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_ids: 101 2413 4171 4614 16371 11818 9733 1010 9130 2000 5806 2041 3617 4171 1024 3027 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:05 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:05 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:05 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   tokens: [CLS] e ##bay ' s seller - po ##achi ##ng allegations against amazon get dismissed by arbitration panel [SEP]\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_ids: 101 1041 15907 1005 1055 14939 1011 13433 21046 3070 9989 2114 9733 2131 7219 2011 18010 5997 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:05 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   tokens: [CLS] india ' s ns ##e warned future retail of action over disclosure ##s on amazon dispute : emails [SEP]\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_ids: 101 2634 1005 1055 24978 2063 7420 2925 7027 1997 2895 2058 19380 2015 2006 9733 7593 1024 22028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   tokens: [CLS] south korea un ##ve ##ils ai chip to maintain semiconductor leadership [SEP]\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_ids: 101 2148 4420 4895 3726 12146 9932 9090 2000 5441 20681 4105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   tokens: [CLS] india ' s ns ##e warned future retail of action over disclosure ##s on amazon dispute - emails [SEP]\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_ids: 101 2634 1005 1055 24978 2063 7420 2925 7027 1997 2895 2058 19380 2015 2006 9733 7593 1011 22028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:06 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:06 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:06 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   tokens: [CLS] 3 top e - commerce stocks to buy ahead of blockbuster black friday sales [SEP]\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_ids: 101 1017 2327 1041 1011 6236 15768 2000 4965 3805 1997 27858 2304 5958 4341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:06 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   tokens: [CLS] venture capitalist ##s discuss the future of gaming [SEP]\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_ids: 101 6957 19640 2015 6848 1996 2925 1997 10355 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   tokens: [CLS] air ##bn ##b prepares to ip ##o [SEP]\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_ids: 101 2250 24700 2497 20776 2000 12997 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:07 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:07 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:07 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   tokens: [CLS] amazon joins fed ##s on anti ##co ##unt ##er ##feit strike force [SEP]\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_ids: 101 9733 9794 7349 2015 2006 3424 3597 16671 2121 21156 4894 2486 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:07 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   tokens: [CLS] dell reports revenue that tops estimates on robust pc demand [SEP]\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_ids: 101 12418 4311 6599 2008 13284 10035 2006 15873 7473 5157 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   tokens: [CLS] fed ##ex stock , ib ##d stock of the day , breaks out ahead of holiday surge [SEP]\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_ids: 101 7349 10288 4518 1010 21307 2094 4518 1997 1996 2154 1010 7807 2041 3805 1997 6209 12058 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:08 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:08 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:08 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   tokens: [CLS] aw ##s announces general availability of amazon managed work ##flow ##s for apache air ##flow [SEP]\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_ids: 101 22091 2015 17472 2236 11343 1997 9733 3266 2147 12314 2015 2005 15895 2250 12314 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:08 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   tokens: [CLS] retailers have no idea what will happen this holiday season [SEP]\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_ids: 101 16629 2031 2053 2801 2054 2097 4148 2023 6209 2161 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   tokens: [CLS] cramer ' s year - end game plan : load up on digital retailers [SEP]\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_ids: 101 29433 1005 1055 2095 1011 2203 2208 2933 1024 7170 2039 2006 3617 16629 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   tokens: [CLS] is amazon . com , inc . ( am ##z ##n ) a good stock to buy according to hedge funds ? [SEP]\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_ids: 101 2003 9733 1012 4012 1010 4297 1012 1006 2572 2480 2078 1007 1037 2204 4518 2000 4965 2429 2000 17834 5029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:09 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:09 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:09 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   tokens: [CLS] better buy : shop ##ify vs . way ##fa ##ir [SEP]\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_ids: 101 2488 4965 1024 4497 8757 5443 1012 2126 7011 4313 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:09 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   tokens: [CLS] 3 index funds perfect for your ira [SEP]\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_ids: 101 1017 5950 5029 3819 2005 2115 11209 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   tokens: [CLS] macy ' s , target , gap and best buy are part of zack ##s earnings preview [SEP]\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_ids: 101 20914 1005 1055 1010 4539 1010 6578 1998 2190 4965 2024 2112 1997 13658 2015 16565 19236 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:10 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:10 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:10 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   tokens: [CLS] newell ' s sun ##beam recalls over 900 , 000 cr ##ock - pot multi - cooke ##rs due to burn hazard [SEP]\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_ids: 101 28052 1005 1055 3103 28302 17722 2058 7706 1010 2199 13675 7432 1011 8962 4800 1011 16546 2869 2349 2000 6402 15559 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:10 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   tokens: [CLS] wal ##mart stock performance has doubled that of the s & p 500 since doing this one thing [SEP]\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_ids: 101 24547 22345 4518 2836 2038 11515 2008 1997 1996 1055 1004 1052 3156 2144 2725 2023 2028 2518 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   tokens: [CLS] black friday 2020 : retail winners and losers [SEP]\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_ids: 101 2304 5958 12609 1024 7027 4791 1998 23160 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:11 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:11 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   tokens: [CLS] 2 e - commerce stocks that are out ##per ##form ##ing amazon [SEP]\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_ids: 101 1016 1041 1011 6236 15768 2008 2024 2041 4842 14192 2075 9733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:11 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   tokens: [CLS] amazon ' s ( am ##z ##n ) new features to ensure spoil - free holiday season [SEP]\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_ids: 101 9733 1005 1055 1006 2572 2480 2078 1007 2047 2838 2000 5676 27594 1011 2489 6209 2161 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   tokens: [CLS] amazon ##s $ 3 , 000 signing bonuses ir ##k workers who got $ 10 coup ##ons [SEP]\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_ids: 101 9733 2015 1002 1017 1010 2199 6608 29563 20868 2243 3667 2040 2288 1002 2184 8648 5644 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   tokens: [CLS] what to make of n ##vid ##ia ' s latest earnings report [SEP]\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_ids: 101 2054 2000 2191 1997 1050 17258 2401 1005 1055 6745 16565 3189 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:12 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:12 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   tokens: [CLS] is this weight loss company coming for w ##w and no ##om ' s market share ? [SEP]\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_ids: 101 2003 2023 3635 3279 2194 2746 2005 1059 2860 1998 2053 5358 1005 1055 3006 3745 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:12 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   tokens: [CLS] ip ##r center , amazon launch operation fulfilled action to stop counter ##feit ##s [SEP]\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_ids: 101 12997 2099 2415 1010 9733 4888 3169 16829 2895 2000 2644 4675 21156 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   tokens: [CLS] 10 stocks to be thankful for this thanksgiving [SEP]\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_ids: 101 2184 15768 2000 2022 18836 2005 2023 15060 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:13 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:13 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:13 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   tokens: [CLS] best buy is latest big retailer to shock everyone by its sales growth during co ##vid - 19 [SEP]\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_ids: 101 2190 4965 2003 6745 2502 20196 2000 5213 3071 2011 2049 4341 3930 2076 2522 17258 1011 2539 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:13 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   tokens: [CLS] netflix in 3 charts [SEP]\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_ids: 101 20907 1999 1017 6093 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   tokens: [CLS] don ##t overlook sales at these 9 retailers [SEP]\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_ids: 101 2123 2102 27590 4341 2012 2122 1023 16629 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:14 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:14 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   tokens: [CLS] amazon brings computer science education to the home classroom with the cyber robotics challenge [SEP]\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_ids: 101 9733 7545 3274 2671 2495 2000 1996 2188 9823 2007 1996 16941 21331 4119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:14 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   tokens: [CLS] microsoft ' s cloud growth continues to pay divide ##nds [SEP]\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_ids: 101 7513 1005 1055 6112 3930 4247 2000 3477 11443 18376 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   tokens: [CLS] 4 robin ##hood stocks billionaire ##s bought in q ##3 [SEP]\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_ids: 101 1018 5863 9021 15768 22301 2015 4149 1999 1053 2509 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   tokens: [CLS] what the vaccine news means for airline stocks [SEP]\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_ids: 101 2054 1996 17404 2739 2965 2005 8582 15768 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:15 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:15 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   tokens: [CLS] za ##land ##o selects aw ##s as its preferred cloud provider [SEP]\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_ids: 101 23564 3122 2080 27034 22091 2015 2004 2049 6871 6112 10802 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:15 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   tokens: [CLS] mer ##ca ##do libre selects aw ##s as its primary cloud provider to accelerate growth and transformation into a data - driven company [SEP]\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_ids: 101 21442 3540 3527 21091 27034 22091 2015 2004 2049 3078 6112 10802 2000 23306 3930 1998 8651 2046 1037 2951 1011 5533 2194 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   tokens: [CLS] we ' re better off without the black friday frenzy [SEP]\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_ids: 101 2057 1005 2128 2488 2125 2302 1996 2304 5958 21517 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:16 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:16 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   tokens: [CLS] even amazon is as cheap as a penny stock - - with fraction ##al shares [SEP]\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_ids: 101 2130 9733 2003 2004 10036 2004 1037 10647 4518 1011 1011 2007 12884 2389 6661 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:16 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   tokens: [CLS] amazon warehouse workers in alabama petition to form a union [SEP]\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_ids: 101 9733 9746 3667 1999 6041 9964 2000 2433 1037 2586 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   tokens: [CLS] corona ##virus : retail workers ' scared ' as cases surge [SEP]\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_ids: 101 21887 23350 1024 7027 3667 1005 6015 1005 2004 3572 12058 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:17 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:17 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   tokens: [CLS] amazon ' s answer to apple air ##pods , the echo buds , can now track workout ##s [SEP]\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_ids: 101 9733 1005 1055 3437 2000 6207 2250 22925 1010 1996 9052 26734 1010 2064 2085 2650 27090 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:17 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:17 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   tokens: [CLS] wal ##mart , amazon workers seek pan ##de ##mic hazard pay [SEP]\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_ids: 101 24547 22345 1010 9733 3667 6148 6090 3207 7712 15559 3477 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   tokens: [CLS] how thanksgiving and black friday affect stocks [SEP]\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_ids: 101 2129 15060 1998 2304 5958 7461 15768 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   tokens: [CLS] why plug power , bloom energy , and clean energy fuels stocks popped monday [SEP]\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_ids: 101 2339 13354 2373 1010 13426 2943 1010 1998 4550 2943 20145 15768 10538 6928 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:18 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:18 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   tokens: [CLS] black friday 2020 will be a smaller event as retailers spread promotions across the holiday season [SEP]\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_ids: 101 2304 5958 12609 2097 2022 1037 3760 2724 2004 16629 3659 15365 2408 1996 6209 2161 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:18 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:19 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:19 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:19 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   tokens: [CLS] party city ceo : it ' s all about the balloons this holiday season [SEP]\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_ids: 101 2283 2103 5766 1024 2009 1005 1055 2035 2055 1996 22163 2023 6209 2161 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:19 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:19 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:19 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   tokens: [CLS] why ceo ##s are uniting against trump ' s election fight [SEP]\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_ids: 101 2339 5766 2015 2024 26112 2114 8398 1005 1055 2602 2954 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   label: None (id = 9090)\n","11/26/2020 22:34:19 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","11/26/2020 22:34:19 - INFO - finbert.utils -   *** Example ***\n","11/26/2020 22:34:19 - INFO - finbert.utils -   guid: 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   tokens: [CLS] 7 most profitable businesses with least investment in 2020 [SEP]\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_ids: 101 1021 2087 15282 5661 2007 2560 5211 1999 12609 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","11/26/2020 22:34:19 - INFO - finbert.utils -   label: None (id = 9090)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":737},"id":"EgfSgxlpgTzA","executionInfo":{"status":"ok","timestamp":1606430060501,"user_tz":300,"elapsed":503072,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"28a2fb40-0649-4a35-bd09-9ab6a09a9875"},"source":["parsed_and_scored_news = pd.read_json(os.path.join(os.path.join(finBERT_repo_path,'data'), 'parsed_and_scored_news.json'))\n","print(parsed_and_scored_news.head())\n","print(parsed_and_scored_news['headline'].head())\n","plt.rcParams['figure.figsize'] = [10, 6]\n","\n","# Group by date and ticker columns from scored_news and calculate the mean\n","mean_scores = parsed_and_scored_news.groupby(['ticker','date']).mean()\n","\n","# Unstack the column ticker\n","mean_scores = mean_scores.unstack()\n","\n","# Get the cross-section of compound in the 'columns' axis\n","mean_scores = mean_scores.xs('scores', axis=\"columns\").transpose()\n","\n","# Plot a bar chart with pandas\n","mean_scores.plot(kind = 'bar')\n","plt.grid()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["    ticker  ...    scores\n","0     AMZN  ... -0.022022\n","1     AMZN  ...  0.056744\n","10    AMZN  ... -0.604638\n","100   TSLA  ... -0.743399\n","101   TSLA  ... -0.320668\n","\n","[5 rows x 5 columns]\n","0      Amazon spends $500m on bonuses for Christmas s...\n","1      The Amazon of Africa is trying to enable third...\n","10     The S&P 500 Could Jump 20% Next Year. Three St...\n","100    Dow Jones, Nasdaq Hit Highs Amid Coronavirus N...\n","101    Tesla (TSLA) Recalls More Than 9,500 SUVs on S...\n","Name: headline, dtype: object\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"eGfKcuXALkF4"},"source":["# TODO:"]},{"cell_type":"markdown","metadata":{"id":"BtwOZLHRTCUI"},"source":["## Train example"]},{"cell_type":"code","metadata":{"id":"be_76ZZ1LWQB"},"source":["%%bash\n","source activate finbert\n","conda env list\n","cd /content/finBERT/\n","\n","python # python code starts here\n","from pathlib import Path\n","import sys\n","sys.path.append('..')\n","import argparse\n","import shutil\n","import os\n","import logging\n","from textblob import TextBlob\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n","from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import *\n","\n","from finbert.finbert import *\n","import finbert.utils as tools\n","from pprint import pprint\n","from sklearn.metrics import classification_report\n","\n","project_dir = Path.cwd()\n","print(project_dir)\n","# finBERT_repo_path = '/content/finBERT'\n","\n","pd.set_option('max_colwidth', -1)\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.ERROR)\n","\n","lm_path = project_dir/'models'/'language_model'/'finbertTRC2'\n","cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n","cl_data_path = project_dir/'data'/'sentiment_data'\n","\n","bertmodel = BertForSequenceClassification.from_pretrained(lm_path,cache_dir=None, num_labels=3)\n","\n","config = Config(   data_dir=cl_data_path,\n","                   bert_model=bertmodel,\n","                   num_train_epochs=4,\n","                   model_dir=cl_path,\n","                   max_seq_length = 48,\n","                   train_batch_size = 32,\n","                   learning_rate = 2e-5,\n","                   output_mode='classification',\n","                   warm_up_proportion=0.2,\n","                   local_rank=-1,\n","                   discriminate=True,\n","                   gradual_unfreeze=True )\n","\n","finbert = FinBert(config)\n","finbert.prepare_model(label_list=['positive','negative','neutral'])\n","\n","# Get the training examples\n","train_data = finbert.get_data('train')\n","model = finbert.create_the_model()\n","\n","# This is for fine-tuning a subset of the model.\n","freeze = 11\n","\n","for param in model.bert.embeddings.parameters():\n","    param.requires_grad = False\n","    \n","for i in range(freeze):\n","    for param in model.bert.encoder.layer[i].parameters():\n","        param.requires_grad = False\n","\n","trained_model = finbert.train(train_examples = train_data, model = model)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zsllAdoo9Jj"},"source":["## Predict using python command\n","\n","*not yet working"]},{"cell_type":"code","metadata":{"id":"Gs86WLi9I79f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606376863848,"user_tz":300,"elapsed":2133,"user":{"displayName":"Olivier Miguel","photoUrl":"","userId":"01489025528635362176"}},"outputId":"313baf19-5b59-485a-a3d4-a0de957268ec"},"source":["%%bash\n","source activate finbert\n","# conda env list\n","# conda list\n","# python -h\n","ls\n","# echo \"$python_predict\"\n","python '/content/finBERT/predict.py' --text_path '/content/finBERT/test.txt' --output_dir  '/content/finBERT/output' --model_path '/content/finBERT/finbert-sentiment-model/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["finBERT\n","gdrive\n","Miniconda3-4.5.4-Linux-x86_64.sh\n","sample_data\n"],"name":"stdout"},{"output_type":"stream","text":["11/26/2020 07:47:43 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/finBERT/finbert-sentiment-model/\n","Traceback (most recent call last):\n","  File \"/content/finBERT/predict.py\", line 28, in <module>\n","    model = BertForSequenceClassification.from_pretrained(args.model_path,num_labels=3,cache_dir=None)\n","  File \"/usr/local/envs/finbert/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\", line 597, in from_pretrained\n","    config = BertConfig.from_json_file(config_file)\n","  File \"/usr/local/envs/finbert/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\", line 206, in from_json_file\n","    with open(json_file, \"r\", encoding='utf-8') as reader:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/finBERT/finbert-sentiment-model/bert_config.json'\n"],"name":"stderr"}]}]}